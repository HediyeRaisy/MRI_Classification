{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7acc946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (1.5.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.9/dist-packages (from pandas) (1.24.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (1.24.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in /home/hedieh/.local/lib/python3.9/site-packages (3.7.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/hedieh/.local/lib/python3.9/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/hedieh/.local/lib/python3.9/site-packages (from matplotlib) (5.12.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.24.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/hedieh/.local/lib/python3.9/site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/hedieh/.local/lib/python3.9/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/hedieh/.local/lib/python3.9/site-packages (from matplotlib) (4.39.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/hedieh/.local/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/hedieh/.local/lib/python3.9/site-packages (from matplotlib) (23.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/hedieh/.local/lib/python3.9/site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/hedieh/.local/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.15.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-23 16:51:52.799557: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-23 16:51:53.237878: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-10-23 16:51:53.237921: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-10-23 16:51:53.237926: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-image in /home/hedieh/.local/lib/python3.9/site-packages (0.20.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/hedieh/.local/lib/python3.9/site-packages (from scikit-image) (23.0)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /home/hedieh/.local/lib/python3.9/site-packages (from scikit-image) (0.1)\n",
      "Requirement already satisfied: pillow>=9.0.1 in /home/hedieh/.local/lib/python3.9/site-packages (from scikit-image) (9.4.0)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /home/hedieh/.local/lib/python3.9/site-packages (from scikit-image) (2.26.0)\n",
      "Requirement already satisfied: scipy<1.9.2,>=1.8 in /home/hedieh/.local/lib/python3.9/site-packages (from scikit-image) (1.9.1)\n",
      "Requirement already satisfied: networkx>=2.8 in /home/hedieh/.local/lib/python3.9/site-packages (from scikit-image) (3.0)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/hedieh/.local/lib/python3.9/site-packages (from scikit-image) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image) (1.24.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /home/hedieh/.local/lib/python3.9/site-packages (from scikit-image) (2023.2.28)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "import pandas as pd\n",
    "!pip install numpy\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm, datasets\n",
    "!pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import keras\n",
    "from keras.layers import Input\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "!pip install scikit-image\n",
    "import skimage.transform as skTrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9485e4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_data_axial(category,patient):\n",
    "    path = \"./data/images/\"+category+\"/axial/\"+patient+\".png\"\n",
    "    return path\n",
    "def path_data_sagital(category,patient):\n",
    "    path = \"./data/images/\"+category+\"/sagital/\"+patient+\".png\"\n",
    "    return path\n",
    "def path_data_coronal(category,patient):\n",
    "    path = \"./data/images/\"+category+\"/coronal/\"+patient+\".png\"\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d40ae4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading datas\n",
    "\n",
    "# total_data = pd.read_csv(\"./total_data_finally.csv\")\n",
    "# PID = total_data[\"Subject ID\"]\n",
    "# Labels = total_data[\"Research Group\"]\n",
    "# total_data\n",
    "total_data = pd.read_csv(\"./total_data.csv\")\n",
    "total_data = total_data[(total_data[\"Research Group\"] != \"MCI\")]\n",
    "total_data = total_data.reset_index()\n",
    "PID = total_data[\"Subject ID\"]\n",
    "Labels = total_data[\"Research Group\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70e04e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths = []\n",
    "# for i in range(0,len(PID)):\n",
    "#     paths.append(path_data(Labels[i],PID[i]))\n",
    "    \n",
    "# paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b56d9e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labels = []\n",
    "for i in Labels:\n",
    "    if i == \"CN\":\n",
    "        new_labels.append(0);\n",
    "    elif i == \"MCI\":\n",
    "        new_labels.append(2);\n",
    "    else:\n",
    "        new_labels.append(1); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3b673c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('002_S_0295', 0, 'CN'),\n",
       " ('002_S_0413', 0, 'CN'),\n",
       " ('002_S_0559', 0, 'CN'),\n",
       " ('002_S_0619', 1, 'AD'),\n",
       " ('002_S_0685', 0, 'CN'),\n",
       " ('002_S_0816', 1, 'AD'),\n",
       " ('002_S_0938', 1, 'AD'),\n",
       " ('002_S_0955', 1, 'AD'),\n",
       " ('002_S_1018', 1, 'AD'),\n",
       " ('002_S_1261', 0, 'CN'),\n",
       " ('002_S_1280', 0, 'CN'),\n",
       " ('002_S_4213', 0, 'CN'),\n",
       " ('002_S_4225', 0, 'CN'),\n",
       " ('002_S_4262', 0, 'CN'),\n",
       " ('002_S_4264', 0, 'CN'),\n",
       " ('002_S_4270', 0, 'CN'),\n",
       " ('002_S_5018', 1, 'AD'),\n",
       " ('002_S_6053', 0, 'CN'),\n",
       " ('003_S_0907', 0, 'CN'),\n",
       " ('003_S_0981', 0, 'CN'),\n",
       " ('003_S_1021', 0, 'CN'),\n",
       " ('003_S_1059', 1, 'AD'),\n",
       " ('003_S_1257', 1, 'AD'),\n",
       " ('003_S_4081', 0, 'CN'),\n",
       " ('003_S_4118', 0, 'CN'),\n",
       " ('003_S_4119', 0, 'CN'),\n",
       " ('003_S_4136', 1, 'AD'),\n",
       " ('003_S_4142', 1, 'AD'),\n",
       " ('003_S_4152', 1, 'AD'),\n",
       " ('003_S_4288', 0, 'CN'),\n",
       " ('003_S_4350', 0, 'CN'),\n",
       " ('003_S_4373', 1, 'AD'),\n",
       " ('003_S_4441', 0, 'CN'),\n",
       " ('003_S_4555', 0, 'CN'),\n",
       " ('003_S_4644', 0, 'CN'),\n",
       " ('003_S_4839', 0, 'CN'),\n",
       " ('003_S_4840', 0, 'CN'),\n",
       " ('003_S_4872', 0, 'CN'),\n",
       " ('003_S_4892', 1, 'AD'),\n",
       " ('003_S_4900', 0, 'CN'),\n",
       " ('003_S_5165', 1, 'AD'),\n",
       " ('003_S_5187', 1, 'AD'),\n",
       " ('005_S_0221', 1, 'AD'),\n",
       " ('005_S_0223', 0, 'CN'),\n",
       " ('005_S_0553', 0, 'CN'),\n",
       " ('005_S_0602', 0, 'CN'),\n",
       " ('005_S_0610', 0, 'CN'),\n",
       " ('005_S_0814', 1, 'AD'),\n",
       " ('005_S_0929', 1, 'AD'),\n",
       " ('005_S_1341', 1, 'AD'),\n",
       " ('005_S_4707', 1, 'AD'),\n",
       " ('005_S_4910', 1, 'AD'),\n",
       " ('005_S_5038', 1, 'AD'),\n",
       " ('005_S_5119', 1, 'AD'),\n",
       " ('006_S_0484', 0, 'CN'),\n",
       " ('006_S_0498', 0, 'CN'),\n",
       " ('006_S_0547', 1, 'AD'),\n",
       " ('006_S_0653', 1, 'AD'),\n",
       " ('006_S_0681', 0, 'CN'),\n",
       " ('006_S_0731', 0, 'CN'),\n",
       " ('006_S_4150', 0, 'CN'),\n",
       " ('006_S_4153', 1, 'AD'),\n",
       " ('006_S_4192', 1, 'AD'),\n",
       " ('006_S_4357', 0, 'CN'),\n",
       " ('006_S_4449', 0, 'CN'),\n",
       " ('006_S_4485', 0, 'CN'),\n",
       " ('006_S_4546', 1, 'AD'),\n",
       " ('006_S_4867', 1, 'AD'),\n",
       " ('007_S_0068', 0, 'CN'),\n",
       " ('007_S_0070', 0, 'CN'),\n",
       " ('007_S_0316', 1, 'AD'),\n",
       " ('007_S_1206', 0, 'CN'),\n",
       " ('007_S_1222', 0, 'CN'),\n",
       " ('007_S_1248', 1, 'AD'),\n",
       " ('007_S_1304', 1, 'AD'),\n",
       " ('007_S_1339', 1, 'AD'),\n",
       " ('007_S_4387', 0, 'CN'),\n",
       " ('007_S_4488', 0, 'CN'),\n",
       " ('007_S_4516', 0, 'CN'),\n",
       " ('007_S_4568', 1, 'AD'),\n",
       " ('007_S_4620', 0, 'CN'),\n",
       " ('007_S_4637', 0, 'CN'),\n",
       " ('007_S_4911', 1, 'AD'),\n",
       " ('007_S_5196', 1, 'AD'),\n",
       " ('009_S_0751', 0, 'CN'),\n",
       " ('009_S_0842', 0, 'CN'),\n",
       " ('009_S_0862', 0, 'CN'),\n",
       " ('009_S_1334', 1, 'AD'),\n",
       " ('009_S_1354', 1, 'AD'),\n",
       " ('009_S_4337', 0, 'CN'),\n",
       " ('009_S_4388', 0, 'CN'),\n",
       " ('009_S_4612', 0, 'CN'),\n",
       " ('009_S_5027', 1, 'AD'),\n",
       " ('009_S_5037', 1, 'AD'),\n",
       " ('009_S_5224', 1, 'AD'),\n",
       " ('009_S_5252', 1, 'AD'),\n",
       " ('010_S_0067', 0, 'CN'),\n",
       " ('010_S_0419', 0, 'CN'),\n",
       " ('010_S_0420', 0, 'CN'),\n",
       " ('010_S_4345', 0, 'CN'),\n",
       " ('010_S_4442', 0, 'CN'),\n",
       " ('010_S_5163', 1, 'AD'),\n",
       " ('011_S_0003', 1, 'AD'),\n",
       " ('011_S_0005', 0, 'CN'),\n",
       " ('011_S_0008', 0, 'CN'),\n",
       " ('011_S_0016', 0, 'CN'),\n",
       " ('011_S_0021', 0, 'CN'),\n",
       " ('011_S_0022', 0, 'CN'),\n",
       " ('011_S_0023', 0, 'CN'),\n",
       " ('011_S_0053', 1, 'AD'),\n",
       " ('011_S_4075', 0, 'CN'),\n",
       " ('011_S_4105', 0, 'CN'),\n",
       " ('011_S_4120', 0, 'CN'),\n",
       " ('011_S_4222', 0, 'CN'),\n",
       " ('011_S_4278', 0, 'CN'),\n",
       " ('011_S_4827', 1, 'AD'),\n",
       " ('011_S_4845', 1, 'AD'),\n",
       " ('011_S_4906', 1, 'AD'),\n",
       " ('011_S_4912', 1, 'AD'),\n",
       " ('011_S_4949', 1, 'AD'),\n",
       " ('012_S_0637', 0, 'CN'),\n",
       " ('012_S_0689', 1, 'AD'),\n",
       " ('012_S_1009', 0, 'CN'),\n",
       " ('012_S_4026', 0, 'CN'),\n",
       " ('012_S_4545', 0, 'CN'),\n",
       " ('013_S_0592', 1, 'AD'),\n",
       " ('013_S_0699', 1, 'AD'),\n",
       " ('013_S_0996', 1, 'AD'),\n",
       " ('013_S_1161', 1, 'AD'),\n",
       " ('013_S_1205', 1, 'AD'),\n",
       " ('013_S_1276', 0, 'CN'),\n",
       " ('013_S_4731', 0, 'CN'),\n",
       " ('013_S_5071', 1, 'AD'),\n",
       " ('014_S_0328', 1, 'AD'),\n",
       " ('014_S_0356', 1, 'AD'),\n",
       " ('014_S_0357', 1, 'AD'),\n",
       " ('014_S_1095', 1, 'AD'),\n",
       " ('014_S_4039', 1, 'AD'),\n",
       " ('014_S_4615', 1, 'AD'),\n",
       " ('016_S_1263', 1, 'AD'),\n",
       " ('016_S_4009', 1, 'AD'),\n",
       " ('016_S_4121', 0, 'CN'),\n",
       " ('016_S_4353', 1, 'AD'),\n",
       " ('016_S_4583', 1, 'AD'),\n",
       " ('016_S_4591', 1, 'AD'),\n",
       " ('016_S_4887', 1, 'AD'),\n",
       " ('018_S_0425', 0, 'CN'),\n",
       " ('018_S_4696', 1, 'AD'),\n",
       " ('019_S_4252', 1, 'AD'),\n",
       " ('019_S_4549', 1, 'AD'),\n",
       " ('020_S_1288', 0, 'CN'),\n",
       " ('023_S_0031', 0, 'CN'),\n",
       " ('023_S_0061', 0, 'CN'),\n",
       " ('023_S_0139', 1, 'AD'),\n",
       " ('023_S_1289', 1, 'AD'),\n",
       " ('027_S_1081', 1, 'AD'),\n",
       " ('027_S_1385', 1, 'AD'),\n",
       " ('029_S_4279', 0, 'CN'),\n",
       " ('029_S_4385', 0, 'CN'),\n",
       " ('031_S_1209', 1, 'AD'),\n",
       " ('032_S_0677', 0, 'CN'),\n",
       " ('037_S_0303', 0, 'CN'),\n",
       " ('067_S_0812', 1, 'AD'),\n",
       " ('067_S_1185', 1, 'AD'),\n",
       " ('067_S_1253', 1, 'AD'),\n",
       " ('094_S_4089', 1, 'AD'),\n",
       " ('094_S_4460', 0, 'CN'),\n",
       " ('098_S_0149', 1, 'AD'),\n",
       " ('098_S_0172', 0, 'CN'),\n",
       " ('100_S_0015', 0, 'CN'),\n",
       " ('100_S_0047', 0, 'CN'),\n",
       " ('100_S_1062', 1, 'AD'),\n",
       " ('100_S_1286', 0, 'CN'),\n",
       " ('123_S_0072', 0, 'CN'),\n",
       " ('123_S_0088', 1, 'AD'),\n",
       " ('123_S_0091', 1, 'AD'),\n",
       " ('123_S_0094', 1, 'AD'),\n",
       " ('123_S_0106', 0, 'CN'),\n",
       " ('123_S_0162', 1, 'AD'),\n",
       " ('126_S_0606', 1, 'AD'),\n",
       " ('126_S_0784', 1, 'AD'),\n",
       " ('127_S_0259', 0, 'CN'),\n",
       " ('127_S_0260', 0, 'CN'),\n",
       " ('127_S_0754', 1, 'AD'),\n",
       " ('127_S_0844', 1, 'AD'),\n",
       " ('129_S_4369', 0, 'CN'),\n",
       " ('130_S_0956', 1, 'AD'),\n",
       " ('130_S_4730', 1, 'AD'),\n",
       " ('131_S_0691', 1, 'AD'),\n",
       " ('133_S_0525', 0, 'CN'),\n",
       " ('003_S_6264', 1, 'AD'),\n",
       " ('003_S_6833', 1, 'AD'),\n",
       " ('006_S_6689', 1, 'AD'),\n",
       " ('011_S_0010', 1, 'AD'),\n",
       " ('011_S_0183', 1, 'AD'),\n",
       " ('011_S_6303', 1, 'AD'),\n",
       " ('013_S_6768', 1, 'AD'),\n",
       " ('013_S_6975', 1, 'AD'),\n",
       " ('016_S_0991', 1, 'AD'),\n",
       " ('016_S_4963', 1, 'AD'),\n",
       " ('016_S_5032', 1, 'AD'),\n",
       " ('016_S_5057', 1, 'AD'),\n",
       " ('016_S_5251', 1, 'AD'),\n",
       " ('016_S_6708', 1, 'AD'),\n",
       " ('016_S_6839', 1, 'AD'),\n",
       " ('018_S_0335', 1, 'AD'),\n",
       " ('018_S_0633', 1, 'AD'),\n",
       " ('018_S_0682', 1, 'AD'),\n",
       " ('018_S_4733', 1, 'AD'),\n",
       " ('018_S_5074', 1, 'AD'),\n",
       " ('018_S_5240', 1, 'AD'),\n",
       " ('019_S_4477', 1, 'AD'),\n",
       " ('019_S_5012', 1, 'AD'),\n",
       " ('019_S_5019', 1, 'AD'),\n",
       " ('019_S_6573', 1, 'AD'),\n",
       " ('019_S_6585', 1, 'AD'),\n",
       " ('019_S_6712', 1, 'AD'),\n",
       " ('020_S_0213', 1, 'AD'),\n",
       " ('021_S_0343', 1, 'AD'),\n",
       " ('021_S_0642', 1, 'AD'),\n",
       " ('021_S_0753', 1, 'AD'),\n",
       " ('021_S_1109', 1, 'AD'),\n",
       " ('021_S_4718', 1, 'AD'),\n",
       " ('021_S_4924', 1, 'AD'),\n",
       " ('022_S_0007', 1, 'AD'),\n",
       " ('022_S_0129', 1, 'AD'),\n",
       " ('022_S_0219', 1, 'AD'),\n",
       " ('022_S_0543', 1, 'AD'),\n",
       " ('022_S_6013', 1, 'AD'),\n",
       " ('022_S_6796', 1, 'AD'),\n",
       " ('023_S_0083', 1, 'AD'),\n",
       " ('023_S_0084', 1, 'AD'),\n",
       " ('023_S_0093', 1, 'AD'),\n",
       " ('023_S_0916', 1, 'AD'),\n",
       " ('023_S_1262', 1, 'AD'),\n",
       " ('023_S_4501', 1, 'AD'),\n",
       " ('023_S_5120', 1, 'AD'),\n",
       " ('023_S_5241', 1, 'AD'),\n",
       " ('023_S_6661', 1, 'AD'),\n",
       " ('024_S_1171', 1, 'AD'),\n",
       " ('024_S_1307', 1, 'AD'),\n",
       " ('024_S_4223', 1, 'AD'),\n",
       " ('024_S_4280', 1, 'AD'),\n",
       " ('024_S_4905', 1, 'AD'),\n",
       " ('024_S_5054', 1, 'AD'),\n",
       " ('027_S_0404', 1, 'AD'),\n",
       " ('027_S_0850', 1, 'AD'),\n",
       " ('027_S_1082', 1, 'AD'),\n",
       " ('027_S_1254', 1, 'AD'),\n",
       " ('027_S_4801', 1, 'AD'),\n",
       " ('027_S_4802', 1, 'AD'),\n",
       " ('027_S_4938', 1, 'AD'),\n",
       " ('027_S_4962', 1, 'AD'),\n",
       " ('027_S_4964', 1, 'AD'),\n",
       " ('027_S_6648', 1, 'AD'),\n",
       " ('027_S_6733', 1, 'AD'),\n",
       " ('027_S_6849', 1, 'AD'),\n",
       " ('027_S_6965', 1, 'AD'),\n",
       " ('029_S_0836', 1, 'AD'),\n",
       " ('029_S_0999', 1, 'AD'),\n",
       " ('029_S_1056', 1, 'AD'),\n",
       " ('029_S_1184', 1, 'AD'),\n",
       " ('029_S_4307', 1, 'AD'),\n",
       " ('031_S_0321', 1, 'AD'),\n",
       " ('031_S_0554', 1, 'AD'),\n",
       " ('031_S_0773', 1, 'AD'),\n",
       " ('031_S_4024', 1, 'AD'),\n",
       " ('032_S_1101', 1, 'AD'),\n",
       " ('032_S_4755', 1, 'AD'),\n",
       " ('032_S_6600', 1, 'AD'),\n",
       " ('032_S_6602', 1, 'AD'),\n",
       " ('032_S_6855', 1, 'AD'),\n",
       " ('033_S_0724', 1, 'AD'),\n",
       " ('033_S_0733', 1, 'AD'),\n",
       " ('033_S_0739', 1, 'AD'),\n",
       " ('033_S_0888', 1, 'AD'),\n",
       " ('033_S_0889', 1, 'AD'),\n",
       " ('033_S_1087', 1, 'AD'),\n",
       " ('033_S_1281', 1, 'AD'),\n",
       " ('033_S_1283', 1, 'AD'),\n",
       " ('033_S_1285', 1, 'AD'),\n",
       " ('033_S_1308', 1, 'AD'),\n",
       " ('033_S_5013', 1, 'AD'),\n",
       " ('033_S_5017', 1, 'AD'),\n",
       " ('033_S_5087', 1, 'AD'),\n",
       " ('033_S_6705', 1, 'AD'),\n",
       " ('033_S_6824', 1, 'AD'),\n",
       " ('033_S_6976', 1, 'AD'),\n",
       " ('033_S_7066', 1, 'AD'),\n",
       " ('035_S_0341', 1, 'AD'),\n",
       " ('035_S_4783', 1, 'AD'),\n",
       " ('035_S_6650', 1, 'AD'),\n",
       " ('035_S_6660', 1, 'AD'),\n",
       " ('035_S_6927', 1, 'AD'),\n",
       " ('035_S_7001', 1, 'AD'),\n",
       " ('036_S_0577', 1, 'AD'),\n",
       " ('036_S_0759', 1, 'AD'),\n",
       " ('036_S_0760', 1, 'AD'),\n",
       " ('036_S_1001', 1, 'AD'),\n",
       " ('036_S_4740', 1, 'AD'),\n",
       " ('036_S_4820', 1, 'AD'),\n",
       " ('036_S_4894', 1, 'AD'),\n",
       " ('036_S_5063', 1, 'AD'),\n",
       " ('036_S_5112', 1, 'AD'),\n",
       " ('036_S_5149', 1, 'AD'),\n",
       " ('036_S_5210', 1, 'AD'),\n",
       " ('036_S_6179', 1, 'AD'),\n",
       " ('036_S_6231', 1, 'AD'),\n",
       " ('037_S_0627', 1, 'AD'),\n",
       " ('037_S_4001', 1, 'AD'),\n",
       " ('037_S_4770', 1, 'AD'),\n",
       " ('037_S_4879', 1, 'AD'),\n",
       " ('037_S_5162', 1, 'AD'),\n",
       " ('037_S_6216', 1, 'AD'),\n",
       " ('037_S_6230', 1, 'AD'),\n",
       " ('037_S_6377', 1, 'AD'),\n",
       " ('041_S_1368', 1, 'AD'),\n",
       " ('041_S_1391', 1, 'AD'),\n",
       " ('041_S_1435', 1, 'AD'),\n",
       " ('051_S_1296', 1, 'AD'),\n",
       " ('051_S_4980', 1, 'AD'),\n",
       " ('051_S_5005', 1, 'AD'),\n",
       " ('052_S_4959', 1, 'AD'),\n",
       " ('052_S_5062', 1, 'AD'),\n",
       " ('052_S_6305', 1, 'AD'),\n",
       " ('053_S_1044', 1, 'AD'),\n",
       " ('053_S_5070', 1, 'AD'),\n",
       " ('053_S_5208', 1, 'AD'),\n",
       " ('053_S_7109', 1, 'AD'),\n",
       " ('057_S_0474', 1, 'AD'),\n",
       " ('057_S_1371', 1, 'AD'),\n",
       " ('057_S_1373', 1, 'AD'),\n",
       " ('057_S_1379', 1, 'AD'),\n",
       " ('057_S_4110', 1, 'AD'),\n",
       " ('057_S_6746', 1, 'AD'),\n",
       " ('057_S_6869', 1, 'AD'),\n",
       " ('062_S_0535', 1, 'AD'),\n",
       " ('062_S_0690', 1, 'AD'),\n",
       " ('062_S_0730', 1, 'AD'),\n",
       " ('062_S_0793', 1, 'AD'),\n",
       " ('067_S_0020', 1, 'AD'),\n",
       " ('067_S_0029', 1, 'AD'),\n",
       " ('067_S_0076', 1, 'AD'),\n",
       " ('067_S_0110', 1, 'AD'),\n",
       " ('067_S_0828', 1, 'AD'),\n",
       " ('067_S_4728', 1, 'AD'),\n",
       " ('067_S_5205', 1, 'AD'),\n",
       " ('067_S_7033', 1, 'AD'),\n",
       " ('068_S_4859', 1, 'AD'),\n",
       " ('068_S_4968', 1, 'AD'),\n",
       " ('068_S_5146', 1, 'AD'),\n",
       " ('068_S_5206', 1, 'AD'),\n",
       " ('070_S_4692', 1, 'AD'),\n",
       " ('070_S_4719', 1, 'AD'),\n",
       " ('073_S_0565', 1, 'AD'),\n",
       " ('073_S_1207', 1, 'AD'),\n",
       " ('073_S_4853', 1, 'AD'),\n",
       " ('073_S_5016', 1, 'AD'),\n",
       " ('073_S_5090', 1, 'AD'),\n",
       " ('082_S_1079', 1, 'AD'),\n",
       " ('082_S_1377', 1, 'AD'),\n",
       " ('082_S_5029', 1, 'AD'),\n",
       " ('082_S_5184', 1, 'AD'),\n",
       " ('082_S_6690', 1, 'AD'),\n",
       " ('094_S_1027', 1, 'AD'),\n",
       " ('094_S_1090', 1, 'AD'),\n",
       " ('094_S_1102', 1, 'AD'),\n",
       " ('094_S_1164', 1, 'AD'),\n",
       " ('094_S_1397', 1, 'AD'),\n",
       " ('094_S_1402', 1, 'AD'),\n",
       " ('094_S_4282', 1, 'AD'),\n",
       " ('094_S_4737', 1, 'AD'),\n",
       " ('094_S_6736', 1, 'AD'),\n",
       " ('098_S_0884', 1, 'AD'),\n",
       " ('098_S_4201', 1, 'AD'),\n",
       " ('098_S_4215', 1, 'AD'),\n",
       " ('098_S_6601', 1, 'AD'),\n",
       " ('098_S_6655', 1, 'AD'),\n",
       " ('098_S_6658', 1, 'AD'),\n",
       " ('099_S_0372', 1, 'AD'),\n",
       " ('099_S_0470', 1, 'AD'),\n",
       " ('099_S_0492', 1, 'AD'),\n",
       " ('099_S_1144', 1, 'AD'),\n",
       " ('099_S_4124', 1, 'AD'),\n",
       " ('099_S_4994', 1, 'AD'),\n",
       " ('100_S_5106', 1, 'AD'),\n",
       " ('100_S_6713', 1, 'AD'),\n",
       " ('109_S_0777', 1, 'AD'),\n",
       " ('109_S_1157', 1, 'AD'),\n",
       " ('109_S_1192', 1, 'AD'),\n",
       " ('002_S_6007', 0, 'CN'),\n",
       " ('002_S_6009', 0, 'CN'),\n",
       " ('002_S_6030', 0, 'CN'),\n",
       " ('002_S_6066', 0, 'CN'),\n",
       " ('002_S_6103', 0, 'CN'),\n",
       " ('002_S_6404', 0, 'CN'),\n",
       " ('002_S_6456', 0, 'CN'),\n",
       " ('002_S_6680', 0, 'CN'),\n",
       " ('003_S_0931', 0, 'CN'),\n",
       " ('003_S_6014', 0, 'CN'),\n",
       " ('003_S_6067', 0, 'CN'),\n",
       " ('003_S_6092', 0, 'CN'),\n",
       " ('003_S_6256', 0, 'CN'),\n",
       " ('003_S_6257', 0, 'CN'),\n",
       " ('003_S_6259', 0, 'CN'),\n",
       " ('003_S_6260', 0, 'CN'),\n",
       " ('003_S_6307', 0, 'CN'),\n",
       " ('003_S_6490', 0, 'CN'),\n",
       " ('003_S_6644', 0, 'CN'),\n",
       " ('003_S_6915', 0, 'CN'),\n",
       " ('003_S_6924', 0, 'CN'),\n",
       " ('003_S_6959', 0, 'CN'),\n",
       " ('003_S_6996', 0, 'CN'),\n",
       " ('003_S_7010', 0, 'CN'),\n",
       " ('005_S_6084', 0, 'CN'),\n",
       " ('005_S_6093', 0, 'CN'),\n",
       " ('005_S_6393', 0, 'CN'),\n",
       " ('006_S_6209', 0, 'CN'),\n",
       " ('006_S_6234', 0, 'CN'),\n",
       " ('006_S_6277', 0, 'CN'),\n",
       " ('006_S_6375', 0, 'CN'),\n",
       " ('006_S_6500', 0, 'CN'),\n",
       " ('007_S_6120', 0, 'CN'),\n",
       " ('007_S_6255', 0, 'CN'),\n",
       " ('007_S_6310', 0, 'CN'),\n",
       " ('007_S_6323', 0, 'CN'),\n",
       " ('007_S_6455', 0, 'CN'),\n",
       " ('007_S_6515', 0, 'CN'),\n",
       " ('007_S_6521', 0, 'CN'),\n",
       " ('009_S_6163', 0, 'CN'),\n",
       " ('009_S_6212', 0, 'CN'),\n",
       " ('009_S_6286', 0, 'CN'),\n",
       " ('010_S_6567', 0, 'CN'),\n",
       " ('011_S_0002', 0, 'CN'),\n",
       " ('011_S_6367', 0, 'CN'),\n",
       " ('011_S_6418', 0, 'CN'),\n",
       " ('011_S_6465', 0, 'CN'),\n",
       " ('011_S_6714', 0, 'CN'),\n",
       " ('011_S_7028', 0, 'CN'),\n",
       " ('011_S_7048', 0, 'CN'),\n",
       " ('011_S_7112', 0, 'CN'),\n",
       " ('012_S_4642', 0, 'CN'),\n",
       " ('012_S_4643', 0, 'CN'),\n",
       " ('013_S_0502', 0, 'CN'),\n",
       " ('013_S_0575', 0, 'CN'),\n",
       " ('013_S_1035', 0, 'CN'),\n",
       " ('013_S_4579', 0, 'CN'),\n",
       " ('013_S_4580', 0, 'CN'),\n",
       " ('013_S_4616', 0, 'CN'),\n",
       " ('013_S_6780', 0, 'CN'),\n",
       " ('013_S_7103', 0, 'CN'),\n",
       " ('014_S_0519', 0, 'CN'),\n",
       " ('014_S_0520', 0, 'CN'),\n",
       " ('014_S_0548', 0, 'CN'),\n",
       " ('014_S_0558', 0, 'CN'),\n",
       " ('014_S_4080', 0, 'CN'),\n",
       " ('014_S_4093', 0, 'CN'),\n",
       " ('014_S_4401', 0, 'CN'),\n",
       " ('014_S_4576', 0, 'CN'),\n",
       " ('014_S_4577', 0, 'CN'),\n",
       " ('014_S_6076', 0, 'CN'),\n",
       " ('014_S_6145', 0, 'CN'),\n",
       " ('014_S_6148', 0, 'CN'),\n",
       " ('014_S_6199', 0, 'CN'),\n",
       " ('014_S_6210', 0, 'CN'),\n",
       " ('014_S_6366', 0, 'CN'),\n",
       " ('014_S_6424', 0, 'CN'),\n",
       " ('014_S_6437', 0, 'CN'),\n",
       " ('014_S_6502', 0, 'CN'),\n",
       " ('014_S_6522', 0, 'CN'),\n",
       " ('014_S_6831', 0, 'CN'),\n",
       " ('014_S_6920', 0, 'CN'),\n",
       " ('014_S_6935', 0, 'CN'),\n",
       " ('014_S_6988', 0, 'CN'),\n",
       " ('014_S_7072', 0, 'CN'),\n",
       " ('014_S_7080', 0, 'CN'),\n",
       " ('016_S_0359', 0, 'CN'),\n",
       " ('016_S_0538', 0, 'CN'),\n",
       " ('016_S_4097', 0, 'CN'),\n",
       " ('016_S_4638', 0, 'CN'),\n",
       " ('016_S_4688', 0, 'CN'),\n",
       " ('016_S_4951', 0, 'CN'),\n",
       " ('016_S_4952', 0, 'CN'),\n",
       " ('016_S_6381', 0, 'CN'),\n",
       " ('016_S_6773', 0, 'CN'),\n",
       " ('016_S_6790', 0, 'CN'),\n",
       " ('016_S_6802', 0, 'CN'),\n",
       " ('016_S_6834', 0, 'CN'),\n",
       " ('016_S_6853', 0, 'CN'),\n",
       " ('016_S_6892', 0, 'CN'),\n",
       " ('016_S_6931', 0, 'CN'),\n",
       " ('016_S_6934', 0, 'CN'),\n",
       " ('016_S_6941', 0, 'CN'),\n",
       " ('016_S_6943', 0, 'CN'),\n",
       " ('016_S_6971', 0, 'CN'),\n",
       " ('018_S_0043', 0, 'CN'),\n",
       " ('018_S_0055', 0, 'CN'),\n",
       " ('018_S_0369', 0, 'CN'),\n",
       " ('018_S_4257', 0, 'CN'),\n",
       " ('018_S_4313', 0, 'CN'),\n",
       " ('018_S_4349', 0, 'CN'),\n",
       " ('018_S_4399', 0, 'CN'),\n",
       " ('018_S_4400', 0, 'CN'),\n",
       " ('018_S_6207', 0, 'CN'),\n",
       " ('018_S_6351', 0, 'CN'),\n",
       " ('019_S_4367', 0, 'CN'),\n",
       " ('019_S_4835', 0, 'CN'),\n",
       " ('019_S_6186', 0, 'CN'),\n",
       " ('019_S_7016', 0, 'CN'),\n",
       " ('020_S_0097', 0, 'CN'),\n",
       " ('020_S_0883', 0, 'CN'),\n",
       " ('020_S_0899', 0, 'CN'),\n",
       " ('020_S_6185', 0, 'CN'),\n",
       " ('020_S_6227', 0, 'CN'),\n",
       " ('020_S_6282', 0, 'CN'),\n",
       " ('020_S_6358', 0, 'CN'),\n",
       " ('020_S_6449', 0, 'CN'),\n",
       " ('020_S_6470', 0, 'CN'),\n",
       " ('020_S_6504', 0, 'CN'),\n",
       " ('020_S_6513', 0, 'CN'),\n",
       " ('020_S_6566', 0, 'CN'),\n",
       " ('021_S_0159', 0, 'CN'),\n",
       " ('021_S_0337', 0, 'CN'),\n",
       " ('021_S_0647', 0, 'CN'),\n",
       " ('021_S_0984', 0, 'CN'),\n",
       " ('021_S_4254', 0, 'CN'),\n",
       " ('021_S_4276', 0, 'CN'),\n",
       " ('021_S_4335', 0, 'CN'),\n",
       " ('021_S_4421', 0, 'CN'),\n",
       " ('021_S_4558', 0, 'CN'),\n",
       " ('021_S_6312', 0, 'CN'),\n",
       " ('021_S_6896', 0, 'CN'),\n",
       " ('021_S_6910', 0, 'CN'),\n",
       " ('021_S_6914', 0, 'CN'),\n",
       " ('021_S_6918', 0, 'CN'),\n",
       " ('021_S_6940', 0, 'CN'),\n",
       " ('021_S_6987', 0, 'CN'),\n",
       " ('021_S_6994', 0, 'CN'),\n",
       " ('021_S_7045', 0, 'CN'),\n",
       " ('021_S_7055', 0, 'CN'),\n",
       " ('021_S_7062', 0, 'CN'),\n",
       " ('021_S_7092', 0, 'CN'),\n",
       " ('022_S_0014', 0, 'CN'),\n",
       " ('022_S_0066', 0, 'CN'),\n",
       " ('022_S_0096', 0, 'CN'),\n",
       " ('022_S_0130', 0, 'CN'),\n",
       " ('022_S_4173', 0, 'CN'),\n",
       " ('022_S_4196', 0, 'CN'),\n",
       " ('022_S_4266', 0, 'CN'),\n",
       " ('022_S_4291', 0, 'CN'),\n",
       " ('022_S_4320', 0, 'CN'),\n",
       " ('022_S_6069', 0, 'CN'),\n",
       " ('022_S_6797', 0, 'CN'),\n",
       " ('022_S_6822', 0, 'CN'),\n",
       " ('023_S_0058', 0, 'CN'),\n",
       " ('023_S_0081', 0, 'CN'),\n",
       " ('023_S_0926', 0, 'CN'),\n",
       " ('023_S_0963', 0, 'CN'),\n",
       " ('023_S_1190', 0, 'CN'),\n",
       " ('023_S_1306', 0, 'CN'),\n",
       " ('023_S_4020', 0, 'CN'),\n",
       " ('023_S_4164', 0, 'CN'),\n",
       " ('023_S_4448', 0, 'CN'),\n",
       " ('023_S_6270', 0, 'CN'),\n",
       " ('023_S_6346', 0, 'CN'),\n",
       " ('023_S_6374', 0, 'CN'),\n",
       " ('023_S_6399', 0, 'CN'),\n",
       " ('023_S_6400', 0, 'CN'),\n",
       " ('023_S_6547', 0, 'CN'),\n",
       " ('023_S_6795', 0, 'CN'),\n",
       " ('024_S_0985', 0, 'CN'),\n",
       " ('024_S_1063', 0, 'CN'),\n",
       " ('024_S_4084', 0, 'CN'),\n",
       " ('024_S_4158', 0, 'CN'),\n",
       " ('024_S_6005', 0, 'CN'),\n",
       " ('024_S_6184', 0, 'CN'),\n",
       " ('024_S_6202', 0, 'CN'),\n",
       " ('024_S_6385', 0, 'CN'),\n",
       " ('024_S_6472', 0, 'CN'),\n",
       " ('027_S_0074', 0, 'CN'),\n",
       " ('027_S_0118', 0, 'CN'),\n",
       " ('027_S_0120', 0, 'CN'),\n",
       " ('027_S_0403', 0, 'CN'),\n",
       " ('027_S_6001', 0, 'CN'),\n",
       " ('027_S_6183', 0, 'CN'),\n",
       " ('027_S_6317', 0, 'CN'),\n",
       " ('027_S_6327', 0, 'CN'),\n",
       " ('027_S_6516', 0, 'CN'),\n",
       " ('027_S_6577', 0, 'CN'),\n",
       " ('027_S_6582', 0, 'CN')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []# List of tuples (image_path, label)\n",
    "for i in range(0,len(PID)):\n",
    "    data.append((PID[i],new_labels[i],Labels[i]))\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4da5187c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hedieh/.local/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hedieh/.local/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from PIL import Image\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "# Define the ResNet-18 model\n",
    "model = models.resnet18(pretrained=True)\n",
    "model\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f155473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data loader and transformations\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path, label = self.data[index]\n",
    "#         img = Image.open(img_path)\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b68930cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "#     transforms.Resize(256),\n",
    "#     transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c3985f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hedieh/.local/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hedieh/.local/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Axial:\n",
      "Fold 1, Train Accuracy: 0.73%, Train F1 Score: 0.73%\n",
      "Sagital:\n",
      "Fold 1, Train Accuracy: 0.72%, Train F1 Score: 0.72%\n",
      "Coronal:\n",
      "Fold 1, Train Accuracy: 0.71%, Train F1 Score: 0.71%\n",
      "Axial\n",
      "Fold 1, Test Accuracy: 0.58%, Test F1 Score: 0.58\n",
      "Sagital\n",
      "Fold 1, Test Accuracy: 0.60%, Test F1 Score: 0.6\n",
      "Coronal\n",
      "Fold 1, Test Accuracy: 0.55%, Test F1 Score: 0.55\n",
      "total\n",
      "Fold 1, Test Accuracy: 0.56%, Test F1 Score: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hedieh/.local/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hedieh/.local/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Axial:\n",
      "Fold 2, Train Accuracy: 0.71%, Train F1 Score: 0.71%\n",
      "Sagital:\n",
      "Fold 2, Train Accuracy: 0.71%, Train F1 Score: 0.71%\n",
      "Coronal:\n",
      "Fold 2, Train Accuracy: 0.72%, Train F1 Score: 0.72%\n",
      "Axial\n",
      "Fold 2, Test Accuracy: 0.53%, Test F1 Score: 0.52\n",
      "Sagital\n",
      "Fold 2, Test Accuracy: 0.63%, Test F1 Score: 0.63\n",
      "Coronal\n",
      "Fold 2, Test Accuracy: 0.57%, Test F1 Score: 0.57\n",
      "total\n",
      "Fold 2, Test Accuracy: 0.66%, Test F1 Score: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hedieh/.local/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hedieh/.local/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 148\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m train_loader_c:\n\u001b[1;32m    147\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 148\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_c\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m    150\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchvision/models/resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchvision/models/resnet.py:273\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    270\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m    271\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxpool(x)\n\u001b[0;32m--> 273\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n\u001b[1;32m    275\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchvision/models/resnet.py:96\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     93\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(out)\n\u001b[1;32m     94\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[0;32m---> 96\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(out)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Define the SVM classifier and its hyperparameters\n",
    "clf_a = svm.SVC(kernel='linear', C=1, gamma='auto',decision_function_shape='ovo')\n",
    "clf_s = svm.SVC(kernel='linear', C=1, gamma='auto',decision_function_shape='ovo')\n",
    "clf_c = svm.SVC(kernel='linear', C=1, gamma='auto',decision_function_shape='ovo')\n",
    "\n",
    "\n",
    "k = 5\n",
    "kf = StratifiedKFold(n_splits=k, shuffle=True)\n",
    "\n",
    "# Train the model using k-fold cross-validation\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(data,new_labels)):\n",
    "    train_data = [data[i] for i in train_idx]\n",
    "    val_data = [data[j] for j in val_idx]\n",
    "    #prepare data for sagital coronal and axial\n",
    "    train_data_s =[]\n",
    "    train_data_a = []\n",
    "    train_data_c = []\n",
    "    for i in train_data:\n",
    "        train_data_s.append((path_data_sagital(str(i[2]),i[0]),i[1]))\n",
    "        train_data_a.append((path_data_sagital(str(i[2]),i[0]),i[1]))\n",
    "        train_data_c.append((path_data_sagital(str(i[2]),i[0]),i[1]))\n",
    "#     print(train_data_c)\n",
    "        \n",
    "    val_data_s =[]\n",
    "    val_data_a = []\n",
    "    val_data_c = []\n",
    "    for i in val_data:\n",
    "        val_data_s.append((path_data_sagital(str(i[2]),i[0]),i[1]))\n",
    "        val_data_a.append((path_data_sagital(str(i[2]),i[0]),i[1]))\n",
    "        val_data_c.append((path_data_sagital(str(i[2]),i[0]),i[1]))\n",
    "        \n",
    "#     print(val_data_c)\n",
    "        \n",
    "    # Define the data loaders for all\n",
    "    train_dataset_a = ImageDataset(train_data_a, transform=transform)\n",
    "    val_dataset_a = ImageDataset(val_data_a, transform=transform)\n",
    "    train_loader_a = DataLoader(train_dataset_a, batch_size=8, shuffle=True)\n",
    "    val_loader_a = DataLoader(val_dataset_a, batch_size=8, shuffle=True)\n",
    "    \n",
    "    train_dataset_s = ImageDataset(train_data_s, transform=transform)\n",
    "    val_dataset_s = ImageDataset(val_data_s, transform=transform)\n",
    "    train_loader_s = DataLoader(train_dataset_s, batch_size=8, shuffle=True)\n",
    "    val_loader_s = DataLoader(val_dataset_s, batch_size=8, shuffle=True)\n",
    "    \n",
    "    train_dataset_c = ImageDataset(train_data_c, transform=transform)\n",
    "    val_dataset_c = ImageDataset(val_data_c, transform=transform)\n",
    "    train_loader_c = DataLoader(train_dataset_c, batch_size=8, shuffle=True)\n",
    "    val_loader_c= DataLoader(val_dataset_c, batch_size=8, shuffle=True)\n",
    "    \n",
    "    # Define the model axial\n",
    "    model_a = torchvision.models.resnet18(pretrained=True)\n",
    "    num_ftrs = model_a.fc.in_features\n",
    "    for param in model_a.parameters():\n",
    "        param.requires_grad = False\n",
    "    model_a.fc = nn.Sequential(nn.Linear(model.fc.in_features, 150),\n",
    "                              nn.ReLU(inplace=True))\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "#     optimizer = optim.SGD(model.parameters(), momentum=0.9, lr=0.001)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Train the model on the training set\n",
    "    # Extract the 128 features from the model for each image in the dataset\n",
    "    train_features_a = []\n",
    "    train_labels_a = []\n",
    "    for epoch in range(30):\n",
    "        model_a.train()\n",
    "        for images, labels in train_loader_a:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model_a(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            train_features_a.append(outputs.detach().numpy())\n",
    "            train_labels_a.append(labels.numpy())\n",
    "            optimizer.step()\n",
    "            \n",
    "    train_features_a = np.array(train_features_a)\n",
    "    train_labels_a = np.array(train_labels_a)\n",
    "    n,x,y = train_features_a.shape\n",
    "    train_features_a = train_features_a.reshape(n*x,y)\n",
    "    n,x = train_labels_a.shape\n",
    "    train_labels_a = train_labels_a.reshape(n*x)\n",
    "    \n",
    "    model_s = torchvision.models.resnet18(pretrained=True)\n",
    "    num_ftrs = model_s.fc.in_features\n",
    "    for param in model_s.parameters():\n",
    "        param.requires_grad = False\n",
    "    model_s.fc = nn.Sequential(nn.Linear(model.fc.in_features, 150),\n",
    "                              nn.ReLU(inplace=True))\n",
    "\n",
    "\n",
    "#  Define the model sagital\n",
    "\n",
    "    train_features_s = []\n",
    "    train_labels_s = []\n",
    "    for epoch in range(30):\n",
    "        model_s.train()\n",
    "        for images, labels in train_loader_s:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model_s(images)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            train_features_s.append(outputs.detach().numpy())\n",
    "            train_labels_s.append(labels.numpy())\n",
    "            optimizer.step()\n",
    "            \n",
    "    train_features_s = np.array(train_features_s)\n",
    "    train_features_s.shape\n",
    "    train_labels_s = np.array(train_labels_s)\n",
    "    n,x,y = train_features_s.shape\n",
    "    train_features_s = train_features_s.reshape(n*x,y)\n",
    "    n,x = train_labels_s.shape\n",
    "    train_labels_s = train_labels_s.reshape(n*x)\n",
    "    \n",
    "    #Define model for Coronal\n",
    "    model_c = torchvision.models.resnet18(pretrained=True)\n",
    "    num_ftrs = model_c.fc.in_features\n",
    "    for param in model_c.parameters():\n",
    "        param.requires_grad = False\n",
    "    model_c.fc = nn.Sequential(nn.Linear(model.fc.in_features, 150),\n",
    "                              nn.ReLU(inplace=True))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    train_features_c = []\n",
    "    train_labels_c = []\n",
    "    for epoch in range(30):\n",
    "        model_c.train()\n",
    "        for images, labels in train_loader_c:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model_c(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            train_features_c.append(outputs.detach().numpy())\n",
    "            train_labels_c.append(labels.numpy())\n",
    "            optimizer.step()\n",
    "            \n",
    "    train_features_c = np.array(train_features_c)\n",
    "    train_features_c.shape\n",
    "    train_labels_c = np.array(train_labels_c)\n",
    "    n,x,y = train_features_c.shape\n",
    "    train_features_c = train_features_c.reshape(n*x,y)\n",
    "    n,x = train_labels_c.shape\n",
    "    train_labels_c = train_labels_c.reshape(n*x)\n",
    "\n",
    "\n",
    "    # Train the SVM classifier on the 128-dimensional feature vectors axial\n",
    "    clf_a.fit(train_features_a, train_labels_a)\n",
    "    train_acc_a = clf_a.score(train_features_a, train_labels_a)\n",
    "    train_f1_a = f1_score(train_labels_a, clf_a.predict(train_features_a), average='macro')\n",
    "    print(\"Axial:\")\n",
    "    print(f'Fold {fold+1}, Train Accuracy: {train_acc_a:.2f}%, Train F1 Score: {train_f1_a:.2f}%')\n",
    "    \n",
    "    # Train the SVM classifier on the 128-dimensional feature vectors sagital\n",
    "    clf_s.fit(train_features_s, train_labels_s)\n",
    "    train_acc_s = clf_s.score(train_features_s, train_labels_s)\n",
    "    train_f1_s = f1_score(train_labels_s, clf_s.predict(train_features_s), average='macro')\n",
    "    print(\"Sagital:\")\n",
    "    print(f'Fold {fold+1}, Train Accuracy: {train_acc_s:.2f}%, Train F1 Score: {train_f1_s:.2f}%')\n",
    "    \n",
    "    # Train the SVM classifier on the 128-dimensional feature vectors coronal\n",
    "    clf_c.fit(train_features_c, train_labels_c)\n",
    "    train_acc_c = clf_c.score(train_features_c, train_labels_c)\n",
    "    train_f1_c = f1_score(train_labels_c, clf_c.predict(train_features_c), average='macro')\n",
    "    print(\"Coronal:\")\n",
    "    print(f'Fold {fold+1}, Train Accuracy: {train_acc_c:.2f}%, Train F1 Score: {train_f1_c:.2f}%')\n",
    "\n",
    "    # Evaluate the model on the test set axial\n",
    "    test_features_a = []\n",
    "    test_labels_a = []\n",
    "    for images, labels in val_loader_a:\n",
    "        outputs = model_a(images)\n",
    "        test_features_a.extend(outputs.detach().numpy())\n",
    "        test_labels_a.extend(labels.numpy())\n",
    "#     print(test_features)\n",
    "    test_features_a = np.array(test_features_a)\n",
    "    test_labels_a = np.array(test_labels_a)\n",
    "    test_acc_a = clf_a.score(test_features_a, test_labels_a)\n",
    "    test_f1_a = f1_score(test_labels_a, clf_a.predict(test_features_a), average='macro')\n",
    "    print(\"Axial\")\n",
    "    print(f'Fold {fold+1}, Test Accuracy: {test_acc_a:.2f}%, Test F1 Score: {test_f1_a:.2}')\n",
    "    \n",
    "    # Evaluate the model on the test set sagital\n",
    "    test_features_s = []\n",
    "    test_labels_s = []\n",
    "    for images, labels in val_loader_s:\n",
    "        outputs = model_s(images)\n",
    "        test_features_s.extend(outputs.detach().numpy())\n",
    "        test_labels_s.extend(labels.numpy())\n",
    "#     print(test_features)\n",
    "    test_features_s = np.array(test_features_s)\n",
    "    test_labels_s = np.array(test_labels_s)\n",
    "    test_acc_s = clf_s.score(test_features_s, test_labels_s)\n",
    "    test_f1_s = f1_score(test_labels_s, clf_s.predict(test_features_s), average='macro')\n",
    "    print(\"Sagital\")\n",
    "    print(f'Fold {fold+1}, Test Accuracy: {test_acc_s:.2f}%, Test F1 Score: {test_f1_s:.2}')\n",
    "    # Evaluate the model on the test set coronal\n",
    "    test_features_c = []\n",
    "    test_labels_c = []\n",
    "    for images, labels in val_loader_c:\n",
    "        outputs = model_c(images)\n",
    "        test_features_c.extend(outputs.detach().numpy())\n",
    "        test_labels_c.extend(labels.numpy())\n",
    "#     print(test_features)\n",
    "    test_features_c = np.array(test_features_c)\n",
    "    test_labels_c = np.array(test_labels_c)\n",
    "    test_acc_c = clf_c.score(test_features_c, test_labels_c)\n",
    "    test_f1_c = f1_score(test_labels_c, clf_c.predict(test_features_c), average='macro')\n",
    "    print(\"Coronal\")\n",
    "    print(f'Fold {fold+1}, Test Accuracy: {test_acc_c:.2f}%, Test F1 Score: {test_f1_c:.2}')\n",
    "    \n",
    "    \n",
    "    #total \n",
    "    total_predicted = []\n",
    "    coronal_p = clf_c.predict(test_features_c)\n",
    "    axial_p = clf_a.predict(test_features_a)\n",
    "    sagital_p = clf_s.predict(test_features_s)\n",
    "    \n",
    "    for i in range(0,len(coronal_p)):\n",
    "        c = coronal_p[i]\n",
    "        a = axial_p[i]\n",
    "        s = sagital_p[i]\n",
    "        if a==s :\n",
    "            total_predicted.append(a)\n",
    "        elif s==c:\n",
    "            total_predicted.append(s)\n",
    "        elif c==a:\n",
    "            total_predicted.append(c)\n",
    "        else:\n",
    "            total_predicted.append(a) \n",
    "    test_acc_t = accuracy_score(test_labels_c, total_predicted)\n",
    "    test_f1_t = f1_score(test_labels_c, total_predicted, average='macro')\n",
    "    print(\"total\")\n",
    "    print(f'Fold {fold+1}, Test Accuracy: {test_acc_t:.2f}%, Test F1 Score: {test_f1_t:.2}')      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd23ba93",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_s.predict(test_features_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6547a24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0b2b6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace95888",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
