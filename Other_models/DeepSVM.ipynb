{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69eeef95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.9/dist-packages (from pandas) (1.24.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (1.24.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in /home/hedieh/.local/lib/python3.9/site-packages (3.7.1)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/hedieh/.local/lib/python3.9/site-packages (from matplotlib) (5.12.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/hedieh/.local/lib/python3.9/site-packages (from matplotlib) (23.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/hedieh/.local/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/hedieh/.local/lib/python3.9/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.24.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/hedieh/.local/lib/python3.9/site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/hedieh/.local/lib/python3.9/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/hedieh/.local/lib/python3.9/site-packages (from matplotlib) (4.39.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/hedieh/.local/lib/python3.9/site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/hedieh/.local/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.15.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-23 16:44:00.103944: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-23 16:44:00.547760: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-10-23 16:44:00.547806: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-10-23 16:44:00.547811: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-image in /home/hedieh/.local/lib/python3.9/site-packages (0.20.0)\n",
      "Requirement already satisfied: pillow>=9.0.1 in /home/hedieh/.local/lib/python3.9/site-packages (from scikit-image) (9.4.0)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/hedieh/.local/lib/python3.9/site-packages (from scikit-image) (1.4.1)\n",
      "Requirement already satisfied: scipy<1.9.2,>=1.8 in /home/hedieh/.local/lib/python3.9/site-packages (from scikit-image) (1.9.1)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /home/hedieh/.local/lib/python3.9/site-packages (from scikit-image) (0.1)\n",
      "Requirement already satisfied: networkx>=2.8 in /home/hedieh/.local/lib/python3.9/site-packages (from scikit-image) (3.0)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /home/hedieh/.local/lib/python3.9/site-packages (from scikit-image) (2.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/hedieh/.local/lib/python3.9/site-packages (from scikit-image) (23.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /home/hedieh/.local/lib/python3.9/site-packages (from scikit-image) (2023.2.28)\n",
      "Requirement already satisfied: numpy>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image) (1.24.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "import pandas as pd\n",
    "!pip install numpy\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm, datasets\n",
    "!pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import keras\n",
    "from keras.layers import Input\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "!pip install scikit-image\n",
    "import skimage.transform as skTrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "016d0f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_data(category,patient):\n",
    "    path = \"./data/images/GM/\"+category+\"/axial/\"+patient+\".png\"\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a3a5749",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading datas\n",
    "\n",
    "total_data = pd.read_csv(\"./total_data.csv\")\n",
    "total_data = total_data[(total_data[\"Research Group\"] != \"MCI\")]\n",
    "total_data = total_data.reset_index()\n",
    "PID = total_data[\"Subject ID\"]\n",
    "Labels = total_data[\"Research Group\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b785254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/images_gray/GM/CN/axial/002_S_0295.png',\n",
       " './data/images_gray/GM/CN/axial/002_S_0413.png',\n",
       " './data/images_gray/GM/CN/axial/002_S_0559.png',\n",
       " './data/images_gray/GM/AD/axial/002_S_0619.png',\n",
       " './data/images_gray/GM/CN/axial/002_S_0685.png',\n",
       " './data/images_gray/GM/AD/axial/002_S_0816.png',\n",
       " './data/images_gray/GM/AD/axial/002_S_0938.png',\n",
       " './data/images_gray/GM/AD/axial/002_S_0955.png',\n",
       " './data/images_gray/GM/AD/axial/002_S_1018.png',\n",
       " './data/images_gray/GM/CN/axial/002_S_1261.png',\n",
       " './data/images_gray/GM/CN/axial/002_S_1280.png',\n",
       " './data/images_gray/GM/CN/axial/002_S_4213.png',\n",
       " './data/images_gray/GM/CN/axial/002_S_4225.png',\n",
       " './data/images_gray/GM/CN/axial/002_S_4262.png',\n",
       " './data/images_gray/GM/CN/axial/002_S_4264.png',\n",
       " './data/images_gray/GM/CN/axial/002_S_4270.png',\n",
       " './data/images_gray/GM/AD/axial/002_S_5018.png',\n",
       " './data/images_gray/GM/CN/axial/002_S_6053.png',\n",
       " './data/images_gray/GM/CN/axial/003_S_0907.png',\n",
       " './data/images_gray/GM/CN/axial/003_S_0981.png',\n",
       " './data/images_gray/GM/CN/axial/003_S_1021.png',\n",
       " './data/images_gray/GM/AD/axial/003_S_1059.png',\n",
       " './data/images_gray/GM/AD/axial/003_S_1257.png',\n",
       " './data/images_gray/GM/CN/axial/003_S_4081.png',\n",
       " './data/images_gray/GM/CN/axial/003_S_4118.png',\n",
       " './data/images_gray/GM/CN/axial/003_S_4119.png',\n",
       " './data/images_gray/GM/AD/axial/003_S_4136.png',\n",
       " './data/images_gray/GM/AD/axial/003_S_4142.png',\n",
       " './data/images_gray/GM/AD/axial/003_S_4152.png',\n",
       " './data/images_gray/GM/CN/axial/003_S_4288.png',\n",
       " './data/images_gray/GM/CN/axial/003_S_4350.png',\n",
       " './data/images_gray/GM/AD/axial/003_S_4373.png',\n",
       " './data/images_gray/GM/CN/axial/003_S_4441.png',\n",
       " './data/images_gray/GM/CN/axial/003_S_4555.png',\n",
       " './data/images_gray/GM/CN/axial/003_S_4644.png',\n",
       " './data/images_gray/GM/CN/axial/003_S_4839.png',\n",
       " './data/images_gray/GM/CN/axial/003_S_4840.png',\n",
       " './data/images_gray/GM/CN/axial/003_S_4872.png',\n",
       " './data/images_gray/GM/AD/axial/003_S_4892.png',\n",
       " './data/images_gray/GM/CN/axial/003_S_4900.png',\n",
       " './data/images_gray/GM/AD/axial/003_S_5165.png',\n",
       " './data/images_gray/GM/AD/axial/003_S_5187.png',\n",
       " './data/images_gray/GM/AD/axial/005_S_0221.png',\n",
       " './data/images_gray/GM/CN/axial/005_S_0223.png',\n",
       " './data/images_gray/GM/CN/axial/005_S_0553.png',\n",
       " './data/images_gray/GM/CN/axial/005_S_0602.png',\n",
       " './data/images_gray/GM/CN/axial/005_S_0610.png',\n",
       " './data/images_gray/GM/AD/axial/005_S_0814.png',\n",
       " './data/images_gray/GM/AD/axial/005_S_0929.png',\n",
       " './data/images_gray/GM/AD/axial/005_S_1341.png',\n",
       " './data/images_gray/GM/AD/axial/005_S_4707.png',\n",
       " './data/images_gray/GM/AD/axial/005_S_4910.png',\n",
       " './data/images_gray/GM/AD/axial/005_S_5038.png',\n",
       " './data/images_gray/GM/AD/axial/005_S_5119.png',\n",
       " './data/images_gray/GM/CN/axial/006_S_0484.png',\n",
       " './data/images_gray/GM/CN/axial/006_S_0498.png',\n",
       " './data/images_gray/GM/AD/axial/006_S_0547.png',\n",
       " './data/images_gray/GM/AD/axial/006_S_0653.png',\n",
       " './data/images_gray/GM/CN/axial/006_S_0681.png',\n",
       " './data/images_gray/GM/CN/axial/006_S_0731.png',\n",
       " './data/images_gray/GM/CN/axial/006_S_4150.png',\n",
       " './data/images_gray/GM/AD/axial/006_S_4153.png',\n",
       " './data/images_gray/GM/AD/axial/006_S_4192.png',\n",
       " './data/images_gray/GM/CN/axial/006_S_4357.png',\n",
       " './data/images_gray/GM/CN/axial/006_S_4449.png',\n",
       " './data/images_gray/GM/CN/axial/006_S_4485.png',\n",
       " './data/images_gray/GM/AD/axial/006_S_4546.png',\n",
       " './data/images_gray/GM/AD/axial/006_S_4867.png',\n",
       " './data/images_gray/GM/CN/axial/007_S_0068.png',\n",
       " './data/images_gray/GM/CN/axial/007_S_0070.png',\n",
       " './data/images_gray/GM/AD/axial/007_S_0316.png',\n",
       " './data/images_gray/GM/CN/axial/007_S_1206.png',\n",
       " './data/images_gray/GM/CN/axial/007_S_1222.png',\n",
       " './data/images_gray/GM/AD/axial/007_S_1248.png',\n",
       " './data/images_gray/GM/AD/axial/007_S_1304.png',\n",
       " './data/images_gray/GM/AD/axial/007_S_1339.png',\n",
       " './data/images_gray/GM/CN/axial/007_S_4387.png',\n",
       " './data/images_gray/GM/CN/axial/007_S_4488.png',\n",
       " './data/images_gray/GM/CN/axial/007_S_4516.png',\n",
       " './data/images_gray/GM/AD/axial/007_S_4568.png',\n",
       " './data/images_gray/GM/CN/axial/007_S_4620.png',\n",
       " './data/images_gray/GM/CN/axial/007_S_4637.png',\n",
       " './data/images_gray/GM/AD/axial/007_S_4911.png',\n",
       " './data/images_gray/GM/AD/axial/007_S_5196.png',\n",
       " './data/images_gray/GM/CN/axial/009_S_0751.png',\n",
       " './data/images_gray/GM/CN/axial/009_S_0842.png',\n",
       " './data/images_gray/GM/CN/axial/009_S_0862.png',\n",
       " './data/images_gray/GM/AD/axial/009_S_1334.png',\n",
       " './data/images_gray/GM/AD/axial/009_S_1354.png',\n",
       " './data/images_gray/GM/CN/axial/009_S_4337.png',\n",
       " './data/images_gray/GM/CN/axial/009_S_4388.png',\n",
       " './data/images_gray/GM/CN/axial/009_S_4612.png',\n",
       " './data/images_gray/GM/AD/axial/009_S_5027.png',\n",
       " './data/images_gray/GM/AD/axial/009_S_5037.png',\n",
       " './data/images_gray/GM/AD/axial/009_S_5224.png',\n",
       " './data/images_gray/GM/AD/axial/009_S_5252.png',\n",
       " './data/images_gray/GM/CN/axial/010_S_0067.png',\n",
       " './data/images_gray/GM/CN/axial/010_S_0419.png',\n",
       " './data/images_gray/GM/CN/axial/010_S_0420.png',\n",
       " './data/images_gray/GM/CN/axial/010_S_4345.png',\n",
       " './data/images_gray/GM/CN/axial/010_S_4442.png',\n",
       " './data/images_gray/GM/AD/axial/010_S_5163.png',\n",
       " './data/images_gray/GM/AD/axial/011_S_0003.png',\n",
       " './data/images_gray/GM/CN/axial/011_S_0005.png',\n",
       " './data/images_gray/GM/CN/axial/011_S_0008.png',\n",
       " './data/images_gray/GM/CN/axial/011_S_0016.png',\n",
       " './data/images_gray/GM/CN/axial/011_S_0021.png',\n",
       " './data/images_gray/GM/CN/axial/011_S_0022.png',\n",
       " './data/images_gray/GM/CN/axial/011_S_0023.png',\n",
       " './data/images_gray/GM/AD/axial/011_S_0053.png',\n",
       " './data/images_gray/GM/CN/axial/011_S_4075.png',\n",
       " './data/images_gray/GM/CN/axial/011_S_4105.png',\n",
       " './data/images_gray/GM/CN/axial/011_S_4120.png',\n",
       " './data/images_gray/GM/CN/axial/011_S_4222.png',\n",
       " './data/images_gray/GM/CN/axial/011_S_4278.png',\n",
       " './data/images_gray/GM/AD/axial/011_S_4827.png',\n",
       " './data/images_gray/GM/AD/axial/011_S_4845.png',\n",
       " './data/images_gray/GM/AD/axial/011_S_4906.png',\n",
       " './data/images_gray/GM/AD/axial/011_S_4912.png',\n",
       " './data/images_gray/GM/AD/axial/011_S_4949.png',\n",
       " './data/images_gray/GM/CN/axial/012_S_0637.png',\n",
       " './data/images_gray/GM/AD/axial/012_S_0689.png',\n",
       " './data/images_gray/GM/CN/axial/012_S_1009.png',\n",
       " './data/images_gray/GM/CN/axial/012_S_4026.png',\n",
       " './data/images_gray/GM/CN/axial/012_S_4545.png',\n",
       " './data/images_gray/GM/AD/axial/013_S_0592.png',\n",
       " './data/images_gray/GM/AD/axial/013_S_0699.png',\n",
       " './data/images_gray/GM/AD/axial/013_S_0996.png',\n",
       " './data/images_gray/GM/AD/axial/013_S_1161.png',\n",
       " './data/images_gray/GM/AD/axial/013_S_1205.png',\n",
       " './data/images_gray/GM/CN/axial/013_S_1276.png',\n",
       " './data/images_gray/GM/CN/axial/013_S_4731.png',\n",
       " './data/images_gray/GM/AD/axial/013_S_5071.png',\n",
       " './data/images_gray/GM/AD/axial/014_S_0328.png',\n",
       " './data/images_gray/GM/AD/axial/014_S_0356.png',\n",
       " './data/images_gray/GM/AD/axial/014_S_0357.png',\n",
       " './data/images_gray/GM/AD/axial/014_S_1095.png',\n",
       " './data/images_gray/GM/AD/axial/014_S_4039.png',\n",
       " './data/images_gray/GM/AD/axial/014_S_4615.png',\n",
       " './data/images_gray/GM/AD/axial/016_S_1263.png',\n",
       " './data/images_gray/GM/AD/axial/016_S_4009.png',\n",
       " './data/images_gray/GM/CN/axial/016_S_4121.png',\n",
       " './data/images_gray/GM/AD/axial/016_S_4353.png',\n",
       " './data/images_gray/GM/AD/axial/016_S_4583.png',\n",
       " './data/images_gray/GM/AD/axial/016_S_4591.png',\n",
       " './data/images_gray/GM/AD/axial/016_S_4887.png',\n",
       " './data/images_gray/GM/CN/axial/018_S_0425.png',\n",
       " './data/images_gray/GM/AD/axial/018_S_4696.png',\n",
       " './data/images_gray/GM/AD/axial/019_S_4252.png',\n",
       " './data/images_gray/GM/AD/axial/019_S_4549.png',\n",
       " './data/images_gray/GM/CN/axial/020_S_1288.png',\n",
       " './data/images_gray/GM/CN/axial/023_S_0031.png',\n",
       " './data/images_gray/GM/CN/axial/023_S_0061.png',\n",
       " './data/images_gray/GM/AD/axial/023_S_0139.png',\n",
       " './data/images_gray/GM/AD/axial/023_S_1289.png',\n",
       " './data/images_gray/GM/AD/axial/027_S_1081.png',\n",
       " './data/images_gray/GM/AD/axial/027_S_1385.png',\n",
       " './data/images_gray/GM/CN/axial/029_S_4279.png',\n",
       " './data/images_gray/GM/CN/axial/029_S_4385.png',\n",
       " './data/images_gray/GM/AD/axial/031_S_1209.png',\n",
       " './data/images_gray/GM/CN/axial/032_S_0677.png',\n",
       " './data/images_gray/GM/CN/axial/037_S_0303.png',\n",
       " './data/images_gray/GM/AD/axial/067_S_0812.png',\n",
       " './data/images_gray/GM/AD/axial/067_S_1185.png',\n",
       " './data/images_gray/GM/AD/axial/067_S_1253.png',\n",
       " './data/images_gray/GM/AD/axial/094_S_4089.png',\n",
       " './data/images_gray/GM/CN/axial/094_S_4460.png',\n",
       " './data/images_gray/GM/AD/axial/098_S_0149.png',\n",
       " './data/images_gray/GM/CN/axial/098_S_0172.png',\n",
       " './data/images_gray/GM/CN/axial/100_S_0015.png',\n",
       " './data/images_gray/GM/CN/axial/100_S_0047.png',\n",
       " './data/images_gray/GM/AD/axial/100_S_1062.png',\n",
       " './data/images_gray/GM/CN/axial/100_S_1286.png',\n",
       " './data/images_gray/GM/CN/axial/123_S_0072.png',\n",
       " './data/images_gray/GM/AD/axial/123_S_0088.png',\n",
       " './data/images_gray/GM/AD/axial/123_S_0091.png',\n",
       " './data/images_gray/GM/AD/axial/123_S_0094.png',\n",
       " './data/images_gray/GM/CN/axial/123_S_0106.png',\n",
       " './data/images_gray/GM/AD/axial/123_S_0162.png',\n",
       " './data/images_gray/GM/AD/axial/126_S_0606.png',\n",
       " './data/images_gray/GM/AD/axial/126_S_0784.png',\n",
       " './data/images_gray/GM/CN/axial/127_S_0259.png',\n",
       " './data/images_gray/GM/CN/axial/127_S_0260.png',\n",
       " './data/images_gray/GM/AD/axial/127_S_0754.png',\n",
       " './data/images_gray/GM/AD/axial/127_S_0844.png',\n",
       " './data/images_gray/GM/CN/axial/129_S_4369.png',\n",
       " './data/images_gray/GM/AD/axial/130_S_0956.png',\n",
       " './data/images_gray/GM/AD/axial/130_S_4730.png',\n",
       " './data/images_gray/GM/AD/axial/131_S_0691.png',\n",
       " './data/images_gray/GM/CN/axial/133_S_0525.png',\n",
       " './data/images_gray/GM/AD/axial/003_S_6264.png',\n",
       " './data/images_gray/GM/AD/axial/003_S_6833.png',\n",
       " './data/images_gray/GM/AD/axial/006_S_6689.png',\n",
       " './data/images_gray/GM/AD/axial/011_S_0010.png',\n",
       " './data/images_gray/GM/AD/axial/011_S_0183.png',\n",
       " './data/images_gray/GM/AD/axial/011_S_6303.png',\n",
       " './data/images_gray/GM/AD/axial/013_S_6768.png',\n",
       " './data/images_gray/GM/AD/axial/013_S_6975.png',\n",
       " './data/images_gray/GM/AD/axial/016_S_0991.png',\n",
       " './data/images_gray/GM/AD/axial/016_S_4963.png',\n",
       " './data/images_gray/GM/AD/axial/016_S_5032.png',\n",
       " './data/images_gray/GM/AD/axial/016_S_5057.png',\n",
       " './data/images_gray/GM/AD/axial/016_S_5251.png',\n",
       " './data/images_gray/GM/AD/axial/016_S_6708.png',\n",
       " './data/images_gray/GM/AD/axial/016_S_6839.png',\n",
       " './data/images_gray/GM/AD/axial/018_S_0335.png',\n",
       " './data/images_gray/GM/AD/axial/018_S_0633.png',\n",
       " './data/images_gray/GM/AD/axial/018_S_0682.png',\n",
       " './data/images_gray/GM/AD/axial/018_S_4733.png',\n",
       " './data/images_gray/GM/AD/axial/018_S_5074.png',\n",
       " './data/images_gray/GM/AD/axial/018_S_5240.png',\n",
       " './data/images_gray/GM/AD/axial/019_S_4477.png',\n",
       " './data/images_gray/GM/AD/axial/019_S_5012.png',\n",
       " './data/images_gray/GM/AD/axial/019_S_5019.png',\n",
       " './data/images_gray/GM/AD/axial/019_S_6573.png',\n",
       " './data/images_gray/GM/AD/axial/019_S_6585.png',\n",
       " './data/images_gray/GM/AD/axial/019_S_6712.png',\n",
       " './data/images_gray/GM/AD/axial/020_S_0213.png',\n",
       " './data/images_gray/GM/AD/axial/021_S_0343.png',\n",
       " './data/images_gray/GM/AD/axial/021_S_0642.png',\n",
       " './data/images_gray/GM/AD/axial/021_S_0753.png',\n",
       " './data/images_gray/GM/AD/axial/021_S_1109.png',\n",
       " './data/images_gray/GM/AD/axial/021_S_4718.png',\n",
       " './data/images_gray/GM/AD/axial/021_S_4924.png',\n",
       " './data/images_gray/GM/AD/axial/022_S_0007.png',\n",
       " './data/images_gray/GM/AD/axial/022_S_0129.png',\n",
       " './data/images_gray/GM/AD/axial/022_S_0219.png',\n",
       " './data/images_gray/GM/AD/axial/022_S_0543.png',\n",
       " './data/images_gray/GM/AD/axial/022_S_6013.png',\n",
       " './data/images_gray/GM/AD/axial/022_S_6796.png',\n",
       " './data/images_gray/GM/AD/axial/023_S_0083.png',\n",
       " './data/images_gray/GM/AD/axial/023_S_0084.png',\n",
       " './data/images_gray/GM/AD/axial/023_S_0093.png',\n",
       " './data/images_gray/GM/AD/axial/023_S_0916.png',\n",
       " './data/images_gray/GM/AD/axial/023_S_1262.png',\n",
       " './data/images_gray/GM/AD/axial/023_S_4501.png',\n",
       " './data/images_gray/GM/AD/axial/023_S_5120.png',\n",
       " './data/images_gray/GM/AD/axial/023_S_5241.png',\n",
       " './data/images_gray/GM/AD/axial/023_S_6661.png',\n",
       " './data/images_gray/GM/AD/axial/024_S_1171.png',\n",
       " './data/images_gray/GM/AD/axial/024_S_1307.png',\n",
       " './data/images_gray/GM/AD/axial/024_S_4223.png',\n",
       " './data/images_gray/GM/AD/axial/024_S_4280.png',\n",
       " './data/images_gray/GM/AD/axial/024_S_4905.png',\n",
       " './data/images_gray/GM/AD/axial/024_S_5054.png',\n",
       " './data/images_gray/GM/AD/axial/027_S_0404.png',\n",
       " './data/images_gray/GM/AD/axial/027_S_0850.png',\n",
       " './data/images_gray/GM/AD/axial/027_S_1082.png',\n",
       " './data/images_gray/GM/AD/axial/027_S_1254.png',\n",
       " './data/images_gray/GM/AD/axial/027_S_4801.png',\n",
       " './data/images_gray/GM/AD/axial/027_S_4802.png',\n",
       " './data/images_gray/GM/AD/axial/027_S_4938.png',\n",
       " './data/images_gray/GM/AD/axial/027_S_4962.png',\n",
       " './data/images_gray/GM/AD/axial/027_S_4964.png',\n",
       " './data/images_gray/GM/AD/axial/027_S_6648.png',\n",
       " './data/images_gray/GM/AD/axial/027_S_6733.png',\n",
       " './data/images_gray/GM/AD/axial/027_S_6849.png',\n",
       " './data/images_gray/GM/AD/axial/027_S_6965.png',\n",
       " './data/images_gray/GM/AD/axial/029_S_0836.png',\n",
       " './data/images_gray/GM/AD/axial/029_S_0999.png',\n",
       " './data/images_gray/GM/AD/axial/029_S_1056.png',\n",
       " './data/images_gray/GM/AD/axial/029_S_1184.png',\n",
       " './data/images_gray/GM/AD/axial/029_S_4307.png',\n",
       " './data/images_gray/GM/AD/axial/031_S_0321.png',\n",
       " './data/images_gray/GM/AD/axial/031_S_0554.png',\n",
       " './data/images_gray/GM/AD/axial/031_S_0773.png',\n",
       " './data/images_gray/GM/AD/axial/031_S_4024.png',\n",
       " './data/images_gray/GM/AD/axial/032_S_1101.png',\n",
       " './data/images_gray/GM/AD/axial/032_S_4755.png',\n",
       " './data/images_gray/GM/AD/axial/032_S_6600.png',\n",
       " './data/images_gray/GM/AD/axial/032_S_6602.png',\n",
       " './data/images_gray/GM/AD/axial/032_S_6855.png',\n",
       " './data/images_gray/GM/AD/axial/033_S_0724.png',\n",
       " './data/images_gray/GM/AD/axial/033_S_0733.png',\n",
       " './data/images_gray/GM/AD/axial/033_S_0739.png',\n",
       " './data/images_gray/GM/AD/axial/033_S_0888.png',\n",
       " './data/images_gray/GM/AD/axial/033_S_0889.png',\n",
       " './data/images_gray/GM/AD/axial/033_S_1087.png',\n",
       " './data/images_gray/GM/AD/axial/033_S_1281.png',\n",
       " './data/images_gray/GM/AD/axial/033_S_1283.png',\n",
       " './data/images_gray/GM/AD/axial/033_S_1285.png',\n",
       " './data/images_gray/GM/AD/axial/033_S_1308.png',\n",
       " './data/images_gray/GM/AD/axial/033_S_5013.png',\n",
       " './data/images_gray/GM/AD/axial/033_S_5017.png',\n",
       " './data/images_gray/GM/AD/axial/033_S_5087.png',\n",
       " './data/images_gray/GM/AD/axial/033_S_6705.png',\n",
       " './data/images_gray/GM/AD/axial/033_S_6824.png',\n",
       " './data/images_gray/GM/AD/axial/033_S_6976.png',\n",
       " './data/images_gray/GM/AD/axial/033_S_7066.png',\n",
       " './data/images_gray/GM/AD/axial/035_S_0341.png',\n",
       " './data/images_gray/GM/AD/axial/035_S_4783.png',\n",
       " './data/images_gray/GM/AD/axial/035_S_6650.png',\n",
       " './data/images_gray/GM/AD/axial/035_S_6660.png',\n",
       " './data/images_gray/GM/AD/axial/035_S_6927.png',\n",
       " './data/images_gray/GM/AD/axial/035_S_7001.png',\n",
       " './data/images_gray/GM/AD/axial/036_S_0577.png',\n",
       " './data/images_gray/GM/AD/axial/036_S_0759.png',\n",
       " './data/images_gray/GM/AD/axial/036_S_0760.png',\n",
       " './data/images_gray/GM/AD/axial/036_S_1001.png',\n",
       " './data/images_gray/GM/AD/axial/036_S_4740.png',\n",
       " './data/images_gray/GM/AD/axial/036_S_4820.png',\n",
       " './data/images_gray/GM/AD/axial/036_S_4894.png',\n",
       " './data/images_gray/GM/AD/axial/036_S_5063.png',\n",
       " './data/images_gray/GM/AD/axial/036_S_5112.png',\n",
       " './data/images_gray/GM/AD/axial/036_S_5149.png',\n",
       " './data/images_gray/GM/AD/axial/036_S_5210.png',\n",
       " './data/images_gray/GM/AD/axial/036_S_6179.png',\n",
       " './data/images_gray/GM/AD/axial/036_S_6231.png',\n",
       " './data/images_gray/GM/AD/axial/037_S_0627.png',\n",
       " './data/images_gray/GM/AD/axial/037_S_4001.png',\n",
       " './data/images_gray/GM/AD/axial/037_S_4770.png',\n",
       " './data/images_gray/GM/AD/axial/037_S_4879.png',\n",
       " './data/images_gray/GM/AD/axial/037_S_5162.png',\n",
       " './data/images_gray/GM/AD/axial/037_S_6216.png',\n",
       " './data/images_gray/GM/AD/axial/037_S_6230.png',\n",
       " './data/images_gray/GM/AD/axial/037_S_6377.png',\n",
       " './data/images_gray/GM/AD/axial/041_S_1368.png',\n",
       " './data/images_gray/GM/AD/axial/041_S_1391.png',\n",
       " './data/images_gray/GM/AD/axial/041_S_1435.png',\n",
       " './data/images_gray/GM/AD/axial/051_S_1296.png',\n",
       " './data/images_gray/GM/AD/axial/051_S_4980.png',\n",
       " './data/images_gray/GM/AD/axial/051_S_5005.png',\n",
       " './data/images_gray/GM/AD/axial/052_S_4959.png',\n",
       " './data/images_gray/GM/AD/axial/052_S_5062.png',\n",
       " './data/images_gray/GM/AD/axial/052_S_6305.png',\n",
       " './data/images_gray/GM/AD/axial/053_S_1044.png',\n",
       " './data/images_gray/GM/AD/axial/053_S_5070.png',\n",
       " './data/images_gray/GM/AD/axial/053_S_5208.png',\n",
       " './data/images_gray/GM/AD/axial/053_S_7109.png',\n",
       " './data/images_gray/GM/AD/axial/057_S_0474.png',\n",
       " './data/images_gray/GM/AD/axial/057_S_1371.png',\n",
       " './data/images_gray/GM/AD/axial/057_S_1373.png',\n",
       " './data/images_gray/GM/AD/axial/057_S_1379.png',\n",
       " './data/images_gray/GM/AD/axial/057_S_4110.png',\n",
       " './data/images_gray/GM/AD/axial/057_S_6746.png',\n",
       " './data/images_gray/GM/AD/axial/057_S_6869.png',\n",
       " './data/images_gray/GM/AD/axial/062_S_0535.png',\n",
       " './data/images_gray/GM/AD/axial/062_S_0690.png',\n",
       " './data/images_gray/GM/AD/axial/062_S_0730.png',\n",
       " './data/images_gray/GM/AD/axial/062_S_0793.png',\n",
       " './data/images_gray/GM/AD/axial/067_S_0020.png',\n",
       " './data/images_gray/GM/AD/axial/067_S_0029.png',\n",
       " './data/images_gray/GM/AD/axial/067_S_0076.png',\n",
       " './data/images_gray/GM/AD/axial/067_S_0110.png',\n",
       " './data/images_gray/GM/AD/axial/067_S_0828.png',\n",
       " './data/images_gray/GM/AD/axial/067_S_4728.png',\n",
       " './data/images_gray/GM/AD/axial/067_S_5205.png',\n",
       " './data/images_gray/GM/AD/axial/067_S_7033.png',\n",
       " './data/images_gray/GM/AD/axial/068_S_4859.png',\n",
       " './data/images_gray/GM/AD/axial/068_S_4968.png',\n",
       " './data/images_gray/GM/AD/axial/068_S_5146.png',\n",
       " './data/images_gray/GM/AD/axial/068_S_5206.png',\n",
       " './data/images_gray/GM/AD/axial/070_S_4692.png',\n",
       " './data/images_gray/GM/AD/axial/070_S_4719.png',\n",
       " './data/images_gray/GM/AD/axial/073_S_0565.png',\n",
       " './data/images_gray/GM/AD/axial/073_S_1207.png',\n",
       " './data/images_gray/GM/AD/axial/073_S_4853.png',\n",
       " './data/images_gray/GM/AD/axial/073_S_5016.png',\n",
       " './data/images_gray/GM/AD/axial/073_S_5090.png',\n",
       " './data/images_gray/GM/AD/axial/082_S_1079.png',\n",
       " './data/images_gray/GM/AD/axial/082_S_1377.png',\n",
       " './data/images_gray/GM/AD/axial/082_S_5029.png',\n",
       " './data/images_gray/GM/AD/axial/082_S_5184.png',\n",
       " './data/images_gray/GM/AD/axial/082_S_6690.png',\n",
       " './data/images_gray/GM/AD/axial/094_S_1027.png',\n",
       " './data/images_gray/GM/AD/axial/094_S_1090.png',\n",
       " './data/images_gray/GM/AD/axial/094_S_1102.png',\n",
       " './data/images_gray/GM/AD/axial/094_S_1164.png',\n",
       " './data/images_gray/GM/AD/axial/094_S_1397.png',\n",
       " './data/images_gray/GM/AD/axial/094_S_1402.png',\n",
       " './data/images_gray/GM/AD/axial/094_S_4282.png',\n",
       " './data/images_gray/GM/AD/axial/094_S_4737.png',\n",
       " './data/images_gray/GM/AD/axial/094_S_6736.png',\n",
       " './data/images_gray/GM/AD/axial/098_S_0884.png',\n",
       " './data/images_gray/GM/AD/axial/098_S_4201.png',\n",
       " './data/images_gray/GM/AD/axial/098_S_4215.png',\n",
       " './data/images_gray/GM/AD/axial/098_S_6601.png',\n",
       " './data/images_gray/GM/AD/axial/098_S_6655.png',\n",
       " './data/images_gray/GM/AD/axial/098_S_6658.png',\n",
       " './data/images_gray/GM/AD/axial/099_S_0372.png',\n",
       " './data/images_gray/GM/AD/axial/099_S_0470.png',\n",
       " './data/images_gray/GM/AD/axial/099_S_0492.png',\n",
       " './data/images_gray/GM/AD/axial/099_S_1144.png',\n",
       " './data/images_gray/GM/AD/axial/099_S_4124.png',\n",
       " './data/images_gray/GM/AD/axial/099_S_4994.png',\n",
       " './data/images_gray/GM/AD/axial/100_S_5106.png',\n",
       " './data/images_gray/GM/AD/axial/100_S_6713.png',\n",
       " './data/images_gray/GM/AD/axial/109_S_0777.png',\n",
       " './data/images_gray/GM/AD/axial/109_S_1157.png',\n",
       " './data/images_gray/GM/AD/axial/109_S_1192.png',\n",
       " './data/images_gray/GM/CN/axial/002_S_6007.png',\n",
       " './data/images_gray/GM/CN/axial/002_S_6009.png',\n",
       " './data/images_gray/GM/CN/axial/002_S_6030.png',\n",
       " './data/images_gray/GM/CN/axial/002_S_6066.png',\n",
       " './data/images_gray/GM/CN/axial/002_S_6103.png',\n",
       " './data/images_gray/GM/CN/axial/002_S_6404.png',\n",
       " './data/images_gray/GM/CN/axial/002_S_6456.png',\n",
       " './data/images_gray/GM/CN/axial/002_S_6680.png',\n",
       " './data/images_gray/GM/CN/axial/003_S_0931.png',\n",
       " './data/images_gray/GM/CN/axial/003_S_6014.png',\n",
       " './data/images_gray/GM/CN/axial/003_S_6067.png',\n",
       " './data/images_gray/GM/CN/axial/003_S_6092.png',\n",
       " './data/images_gray/GM/CN/axial/003_S_6256.png',\n",
       " './data/images_gray/GM/CN/axial/003_S_6257.png',\n",
       " './data/images_gray/GM/CN/axial/003_S_6259.png',\n",
       " './data/images_gray/GM/CN/axial/003_S_6260.png',\n",
       " './data/images_gray/GM/CN/axial/003_S_6307.png',\n",
       " './data/images_gray/GM/CN/axial/003_S_6490.png',\n",
       " './data/images_gray/GM/CN/axial/003_S_6644.png',\n",
       " './data/images_gray/GM/CN/axial/003_S_6915.png',\n",
       " './data/images_gray/GM/CN/axial/003_S_6924.png',\n",
       " './data/images_gray/GM/CN/axial/003_S_6959.png',\n",
       " './data/images_gray/GM/CN/axial/003_S_6996.png',\n",
       " './data/images_gray/GM/CN/axial/003_S_7010.png',\n",
       " './data/images_gray/GM/CN/axial/005_S_6084.png',\n",
       " './data/images_gray/GM/CN/axial/005_S_6093.png',\n",
       " './data/images_gray/GM/CN/axial/005_S_6393.png',\n",
       " './data/images_gray/GM/CN/axial/006_S_6209.png',\n",
       " './data/images_gray/GM/CN/axial/006_S_6234.png',\n",
       " './data/images_gray/GM/CN/axial/006_S_6277.png',\n",
       " './data/images_gray/GM/CN/axial/006_S_6375.png',\n",
       " './data/images_gray/GM/CN/axial/006_S_6500.png',\n",
       " './data/images_gray/GM/CN/axial/007_S_6120.png',\n",
       " './data/images_gray/GM/CN/axial/007_S_6255.png',\n",
       " './data/images_gray/GM/CN/axial/007_S_6310.png',\n",
       " './data/images_gray/GM/CN/axial/007_S_6323.png',\n",
       " './data/images_gray/GM/CN/axial/007_S_6455.png',\n",
       " './data/images_gray/GM/CN/axial/007_S_6515.png',\n",
       " './data/images_gray/GM/CN/axial/007_S_6521.png',\n",
       " './data/images_gray/GM/CN/axial/009_S_6163.png',\n",
       " './data/images_gray/GM/CN/axial/009_S_6212.png',\n",
       " './data/images_gray/GM/CN/axial/009_S_6286.png',\n",
       " './data/images_gray/GM/CN/axial/010_S_6567.png',\n",
       " './data/images_gray/GM/CN/axial/011_S_0002.png',\n",
       " './data/images_gray/GM/CN/axial/011_S_6367.png',\n",
       " './data/images_gray/GM/CN/axial/011_S_6418.png',\n",
       " './data/images_gray/GM/CN/axial/011_S_6465.png',\n",
       " './data/images_gray/GM/CN/axial/011_S_6714.png',\n",
       " './data/images_gray/GM/CN/axial/011_S_7028.png',\n",
       " './data/images_gray/GM/CN/axial/011_S_7048.png',\n",
       " './data/images_gray/GM/CN/axial/011_S_7112.png',\n",
       " './data/images_gray/GM/CN/axial/012_S_4642.png',\n",
       " './data/images_gray/GM/CN/axial/012_S_4643.png',\n",
       " './data/images_gray/GM/CN/axial/013_S_0502.png',\n",
       " './data/images_gray/GM/CN/axial/013_S_0575.png',\n",
       " './data/images_gray/GM/CN/axial/013_S_1035.png',\n",
       " './data/images_gray/GM/CN/axial/013_S_4579.png',\n",
       " './data/images_gray/GM/CN/axial/013_S_4580.png',\n",
       " './data/images_gray/GM/CN/axial/013_S_4616.png',\n",
       " './data/images_gray/GM/CN/axial/013_S_6780.png',\n",
       " './data/images_gray/GM/CN/axial/013_S_7103.png',\n",
       " './data/images_gray/GM/CN/axial/014_S_0519.png',\n",
       " './data/images_gray/GM/CN/axial/014_S_0520.png',\n",
       " './data/images_gray/GM/CN/axial/014_S_0548.png',\n",
       " './data/images_gray/GM/CN/axial/014_S_0558.png',\n",
       " './data/images_gray/GM/CN/axial/014_S_4080.png',\n",
       " './data/images_gray/GM/CN/axial/014_S_4093.png',\n",
       " './data/images_gray/GM/CN/axial/014_S_4401.png',\n",
       " './data/images_gray/GM/CN/axial/014_S_4576.png',\n",
       " './data/images_gray/GM/CN/axial/014_S_4577.png',\n",
       " './data/images_gray/GM/CN/axial/014_S_6076.png',\n",
       " './data/images_gray/GM/CN/axial/014_S_6145.png',\n",
       " './data/images_gray/GM/CN/axial/014_S_6148.png',\n",
       " './data/images_gray/GM/CN/axial/014_S_6199.png',\n",
       " './data/images_gray/GM/CN/axial/014_S_6210.png',\n",
       " './data/images_gray/GM/CN/axial/014_S_6366.png',\n",
       " './data/images_gray/GM/CN/axial/014_S_6424.png',\n",
       " './data/images_gray/GM/CN/axial/014_S_6437.png',\n",
       " './data/images_gray/GM/CN/axial/014_S_6502.png',\n",
       " './data/images_gray/GM/CN/axial/014_S_6522.png',\n",
       " './data/images_gray/GM/CN/axial/014_S_6831.png',\n",
       " './data/images_gray/GM/CN/axial/014_S_6920.png',\n",
       " './data/images_gray/GM/CN/axial/014_S_6935.png',\n",
       " './data/images_gray/GM/CN/axial/014_S_6988.png',\n",
       " './data/images_gray/GM/CN/axial/014_S_7072.png',\n",
       " './data/images_gray/GM/CN/axial/014_S_7080.png',\n",
       " './data/images_gray/GM/CN/axial/016_S_0359.png',\n",
       " './data/images_gray/GM/CN/axial/016_S_0538.png',\n",
       " './data/images_gray/GM/CN/axial/016_S_4097.png',\n",
       " './data/images_gray/GM/CN/axial/016_S_4638.png',\n",
       " './data/images_gray/GM/CN/axial/016_S_4688.png',\n",
       " './data/images_gray/GM/CN/axial/016_S_4951.png',\n",
       " './data/images_gray/GM/CN/axial/016_S_4952.png',\n",
       " './data/images_gray/GM/CN/axial/016_S_6381.png',\n",
       " './data/images_gray/GM/CN/axial/016_S_6773.png',\n",
       " './data/images_gray/GM/CN/axial/016_S_6790.png',\n",
       " './data/images_gray/GM/CN/axial/016_S_6802.png',\n",
       " './data/images_gray/GM/CN/axial/016_S_6834.png',\n",
       " './data/images_gray/GM/CN/axial/016_S_6853.png',\n",
       " './data/images_gray/GM/CN/axial/016_S_6892.png',\n",
       " './data/images_gray/GM/CN/axial/016_S_6931.png',\n",
       " './data/images_gray/GM/CN/axial/016_S_6934.png',\n",
       " './data/images_gray/GM/CN/axial/016_S_6941.png',\n",
       " './data/images_gray/GM/CN/axial/016_S_6943.png',\n",
       " './data/images_gray/GM/CN/axial/016_S_6971.png',\n",
       " './data/images_gray/GM/CN/axial/018_S_0043.png',\n",
       " './data/images_gray/GM/CN/axial/018_S_0055.png',\n",
       " './data/images_gray/GM/CN/axial/018_S_0369.png',\n",
       " './data/images_gray/GM/CN/axial/018_S_4257.png',\n",
       " './data/images_gray/GM/CN/axial/018_S_4313.png',\n",
       " './data/images_gray/GM/CN/axial/018_S_4349.png',\n",
       " './data/images_gray/GM/CN/axial/018_S_4399.png',\n",
       " './data/images_gray/GM/CN/axial/018_S_4400.png',\n",
       " './data/images_gray/GM/CN/axial/018_S_6207.png',\n",
       " './data/images_gray/GM/CN/axial/018_S_6351.png',\n",
       " './data/images_gray/GM/CN/axial/019_S_4367.png',\n",
       " './data/images_gray/GM/CN/axial/019_S_4835.png',\n",
       " './data/images_gray/GM/CN/axial/019_S_6186.png',\n",
       " './data/images_gray/GM/CN/axial/019_S_7016.png',\n",
       " './data/images_gray/GM/CN/axial/020_S_0097.png',\n",
       " './data/images_gray/GM/CN/axial/020_S_0883.png',\n",
       " './data/images_gray/GM/CN/axial/020_S_0899.png',\n",
       " './data/images_gray/GM/CN/axial/020_S_6185.png',\n",
       " './data/images_gray/GM/CN/axial/020_S_6227.png',\n",
       " './data/images_gray/GM/CN/axial/020_S_6282.png',\n",
       " './data/images_gray/GM/CN/axial/020_S_6358.png',\n",
       " './data/images_gray/GM/CN/axial/020_S_6449.png',\n",
       " './data/images_gray/GM/CN/axial/020_S_6470.png',\n",
       " './data/images_gray/GM/CN/axial/020_S_6504.png',\n",
       " './data/images_gray/GM/CN/axial/020_S_6513.png',\n",
       " './data/images_gray/GM/CN/axial/020_S_6566.png',\n",
       " './data/images_gray/GM/CN/axial/021_S_0159.png',\n",
       " './data/images_gray/GM/CN/axial/021_S_0337.png',\n",
       " './data/images_gray/GM/CN/axial/021_S_0647.png',\n",
       " './data/images_gray/GM/CN/axial/021_S_0984.png',\n",
       " './data/images_gray/GM/CN/axial/021_S_4254.png',\n",
       " './data/images_gray/GM/CN/axial/021_S_4276.png',\n",
       " './data/images_gray/GM/CN/axial/021_S_4335.png',\n",
       " './data/images_gray/GM/CN/axial/021_S_4421.png',\n",
       " './data/images_gray/GM/CN/axial/021_S_4558.png',\n",
       " './data/images_gray/GM/CN/axial/021_S_6312.png',\n",
       " './data/images_gray/GM/CN/axial/021_S_6896.png',\n",
       " './data/images_gray/GM/CN/axial/021_S_6910.png',\n",
       " './data/images_gray/GM/CN/axial/021_S_6914.png',\n",
       " './data/images_gray/GM/CN/axial/021_S_6918.png',\n",
       " './data/images_gray/GM/CN/axial/021_S_6940.png',\n",
       " './data/images_gray/GM/CN/axial/021_S_6987.png',\n",
       " './data/images_gray/GM/CN/axial/021_S_6994.png',\n",
       " './data/images_gray/GM/CN/axial/021_S_7045.png',\n",
       " './data/images_gray/GM/CN/axial/021_S_7055.png',\n",
       " './data/images_gray/GM/CN/axial/021_S_7062.png',\n",
       " './data/images_gray/GM/CN/axial/021_S_7092.png',\n",
       " './data/images_gray/GM/CN/axial/022_S_0014.png',\n",
       " './data/images_gray/GM/CN/axial/022_S_0066.png',\n",
       " './data/images_gray/GM/CN/axial/022_S_0096.png',\n",
       " './data/images_gray/GM/CN/axial/022_S_0130.png',\n",
       " './data/images_gray/GM/CN/axial/022_S_4173.png',\n",
       " './data/images_gray/GM/CN/axial/022_S_4196.png',\n",
       " './data/images_gray/GM/CN/axial/022_S_4266.png',\n",
       " './data/images_gray/GM/CN/axial/022_S_4291.png',\n",
       " './data/images_gray/GM/CN/axial/022_S_4320.png',\n",
       " './data/images_gray/GM/CN/axial/022_S_6069.png',\n",
       " './data/images_gray/GM/CN/axial/022_S_6797.png',\n",
       " './data/images_gray/GM/CN/axial/022_S_6822.png',\n",
       " './data/images_gray/GM/CN/axial/023_S_0058.png',\n",
       " './data/images_gray/GM/CN/axial/023_S_0081.png',\n",
       " './data/images_gray/GM/CN/axial/023_S_0926.png',\n",
       " './data/images_gray/GM/CN/axial/023_S_0963.png',\n",
       " './data/images_gray/GM/CN/axial/023_S_1190.png',\n",
       " './data/images_gray/GM/CN/axial/023_S_1306.png',\n",
       " './data/images_gray/GM/CN/axial/023_S_4020.png',\n",
       " './data/images_gray/GM/CN/axial/023_S_4164.png',\n",
       " './data/images_gray/GM/CN/axial/023_S_4448.png',\n",
       " './data/images_gray/GM/CN/axial/023_S_6270.png',\n",
       " './data/images_gray/GM/CN/axial/023_S_6346.png',\n",
       " './data/images_gray/GM/CN/axial/023_S_6374.png',\n",
       " './data/images_gray/GM/CN/axial/023_S_6399.png',\n",
       " './data/images_gray/GM/CN/axial/023_S_6400.png',\n",
       " './data/images_gray/GM/CN/axial/023_S_6547.png',\n",
       " './data/images_gray/GM/CN/axial/023_S_6795.png',\n",
       " './data/images_gray/GM/CN/axial/024_S_0985.png',\n",
       " './data/images_gray/GM/CN/axial/024_S_1063.png',\n",
       " './data/images_gray/GM/CN/axial/024_S_4084.png',\n",
       " './data/images_gray/GM/CN/axial/024_S_4158.png',\n",
       " './data/images_gray/GM/CN/axial/024_S_6005.png',\n",
       " './data/images_gray/GM/CN/axial/024_S_6184.png',\n",
       " './data/images_gray/GM/CN/axial/024_S_6202.png',\n",
       " './data/images_gray/GM/CN/axial/024_S_6385.png',\n",
       " './data/images_gray/GM/CN/axial/024_S_6472.png',\n",
       " './data/images_gray/GM/CN/axial/027_S_0074.png',\n",
       " './data/images_gray/GM/CN/axial/027_S_0118.png',\n",
       " './data/images_gray/GM/CN/axial/027_S_0120.png',\n",
       " './data/images_gray/GM/CN/axial/027_S_0403.png',\n",
       " './data/images_gray/GM/CN/axial/027_S_6001.png',\n",
       " './data/images_gray/GM/CN/axial/027_S_6183.png',\n",
       " './data/images_gray/GM/CN/axial/027_S_6317.png',\n",
       " './data/images_gray/GM/CN/axial/027_S_6327.png',\n",
       " './data/images_gray/GM/CN/axial/027_S_6516.png',\n",
       " './data/images_gray/GM/CN/axial/027_S_6577.png',\n",
       " './data/images_gray/GM/CN/axial/027_S_6582.png']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = []\n",
    "for i in range(0,len(PID)):\n",
    "    paths.append(path_data(Labels[i],PID[i]))\n",
    "    \n",
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db09ba46",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labels = []\n",
    "for i in Labels:\n",
    "    if i == \"CN\":\n",
    "        new_labels.append(0);\n",
    "    elif i == \"MCI\":\n",
    "        new_labels.append(2);\n",
    "    else:\n",
    "        new_labels.append(1); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "715b1ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('./data/images_gray/GM/CN/axial/002_S_0295.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/002_S_0413.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/002_S_0559.png', 0),\n",
       " ('./data/images_gray/GM/AD/axial/002_S_0619.png', 1),\n",
       " ('./data/images_gray/GM/CN/axial/002_S_0685.png', 0),\n",
       " ('./data/images_gray/GM/AD/axial/002_S_0816.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/002_S_0938.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/002_S_0955.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/002_S_1018.png', 1),\n",
       " ('./data/images_gray/GM/CN/axial/002_S_1261.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/002_S_1280.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/002_S_4213.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/002_S_4225.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/002_S_4262.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/002_S_4264.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/002_S_4270.png', 0),\n",
       " ('./data/images_gray/GM/AD/axial/002_S_5018.png', 1),\n",
       " ('./data/images_gray/GM/CN/axial/002_S_6053.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/003_S_0907.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/003_S_0981.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/003_S_1021.png', 0),\n",
       " ('./data/images_gray/GM/AD/axial/003_S_1059.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/003_S_1257.png', 1),\n",
       " ('./data/images_gray/GM/CN/axial/003_S_4081.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/003_S_4118.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/003_S_4119.png', 0),\n",
       " ('./data/images_gray/GM/AD/axial/003_S_4136.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/003_S_4142.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/003_S_4152.png', 1),\n",
       " ('./data/images_gray/GM/CN/axial/003_S_4288.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/003_S_4350.png', 0),\n",
       " ('./data/images_gray/GM/AD/axial/003_S_4373.png', 1),\n",
       " ('./data/images_gray/GM/CN/axial/003_S_4441.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/003_S_4555.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/003_S_4644.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/003_S_4839.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/003_S_4840.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/003_S_4872.png', 0),\n",
       " ('./data/images_gray/GM/AD/axial/003_S_4892.png', 1),\n",
       " ('./data/images_gray/GM/CN/axial/003_S_4900.png', 0),\n",
       " ('./data/images_gray/GM/AD/axial/003_S_5165.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/003_S_5187.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/005_S_0221.png', 1),\n",
       " ('./data/images_gray/GM/CN/axial/005_S_0223.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/005_S_0553.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/005_S_0602.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/005_S_0610.png', 0),\n",
       " ('./data/images_gray/GM/AD/axial/005_S_0814.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/005_S_0929.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/005_S_1341.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/005_S_4707.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/005_S_4910.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/005_S_5038.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/005_S_5119.png', 1),\n",
       " ('./data/images_gray/GM/CN/axial/006_S_0484.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/006_S_0498.png', 0),\n",
       " ('./data/images_gray/GM/AD/axial/006_S_0547.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/006_S_0653.png', 1),\n",
       " ('./data/images_gray/GM/CN/axial/006_S_0681.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/006_S_0731.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/006_S_4150.png', 0),\n",
       " ('./data/images_gray/GM/AD/axial/006_S_4153.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/006_S_4192.png', 1),\n",
       " ('./data/images_gray/GM/CN/axial/006_S_4357.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/006_S_4449.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/006_S_4485.png', 0),\n",
       " ('./data/images_gray/GM/AD/axial/006_S_4546.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/006_S_4867.png', 1),\n",
       " ('./data/images_gray/GM/CN/axial/007_S_0068.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/007_S_0070.png', 0),\n",
       " ('./data/images_gray/GM/AD/axial/007_S_0316.png', 1),\n",
       " ('./data/images_gray/GM/CN/axial/007_S_1206.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/007_S_1222.png', 0),\n",
       " ('./data/images_gray/GM/AD/axial/007_S_1248.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/007_S_1304.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/007_S_1339.png', 1),\n",
       " ('./data/images_gray/GM/CN/axial/007_S_4387.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/007_S_4488.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/007_S_4516.png', 0),\n",
       " ('./data/images_gray/GM/AD/axial/007_S_4568.png', 1),\n",
       " ('./data/images_gray/GM/CN/axial/007_S_4620.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/007_S_4637.png', 0),\n",
       " ('./data/images_gray/GM/AD/axial/007_S_4911.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/007_S_5196.png', 1),\n",
       " ('./data/images_gray/GM/CN/axial/009_S_0751.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/009_S_0842.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/009_S_0862.png', 0),\n",
       " ('./data/images_gray/GM/AD/axial/009_S_1334.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/009_S_1354.png', 1),\n",
       " ('./data/images_gray/GM/CN/axial/009_S_4337.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/009_S_4388.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/009_S_4612.png', 0),\n",
       " ('./data/images_gray/GM/AD/axial/009_S_5027.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/009_S_5037.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/009_S_5224.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/009_S_5252.png', 1),\n",
       " ('./data/images_gray/GM/CN/axial/010_S_0067.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/010_S_0419.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/010_S_0420.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/010_S_4345.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/010_S_4442.png', 0),\n",
       " ('./data/images_gray/GM/AD/axial/010_S_5163.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/011_S_0003.png', 1),\n",
       " ('./data/images_gray/GM/CN/axial/011_S_0005.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/011_S_0008.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/011_S_0016.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/011_S_0021.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/011_S_0022.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/011_S_0023.png', 0),\n",
       " ('./data/images_gray/GM/AD/axial/011_S_0053.png', 1),\n",
       " ('./data/images_gray/GM/CN/axial/011_S_4075.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/011_S_4105.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/011_S_4120.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/011_S_4222.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/011_S_4278.png', 0),\n",
       " ('./data/images_gray/GM/AD/axial/011_S_4827.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/011_S_4845.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/011_S_4906.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/011_S_4912.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/011_S_4949.png', 1),\n",
       " ('./data/images_gray/GM/CN/axial/012_S_0637.png', 0),\n",
       " ('./data/images_gray/GM/AD/axial/012_S_0689.png', 1),\n",
       " ('./data/images_gray/GM/CN/axial/012_S_1009.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/012_S_4026.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/012_S_4545.png', 0),\n",
       " ('./data/images_gray/GM/AD/axial/013_S_0592.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/013_S_0699.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/013_S_0996.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/013_S_1161.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/013_S_1205.png', 1),\n",
       " ('./data/images_gray/GM/CN/axial/013_S_1276.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/013_S_4731.png', 0),\n",
       " ('./data/images_gray/GM/AD/axial/013_S_5071.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/014_S_0328.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/014_S_0356.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/014_S_0357.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/014_S_1095.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/014_S_4039.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/014_S_4615.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/016_S_1263.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/016_S_4009.png', 1),\n",
       " ('./data/images_gray/GM/CN/axial/016_S_4121.png', 0),\n",
       " ('./data/images_gray/GM/AD/axial/016_S_4353.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/016_S_4583.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/016_S_4591.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/016_S_4887.png', 1),\n",
       " ('./data/images_gray/GM/CN/axial/018_S_0425.png', 0),\n",
       " ('./data/images_gray/GM/AD/axial/018_S_4696.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/019_S_4252.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/019_S_4549.png', 1),\n",
       " ('./data/images_gray/GM/CN/axial/020_S_1288.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/023_S_0031.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/023_S_0061.png', 0),\n",
       " ('./data/images_gray/GM/AD/axial/023_S_0139.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/023_S_1289.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/027_S_1081.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/027_S_1385.png', 1),\n",
       " ('./data/images_gray/GM/CN/axial/029_S_4279.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/029_S_4385.png', 0),\n",
       " ('./data/images_gray/GM/AD/axial/031_S_1209.png', 1),\n",
       " ('./data/images_gray/GM/CN/axial/032_S_0677.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/037_S_0303.png', 0),\n",
       " ('./data/images_gray/GM/AD/axial/067_S_0812.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/067_S_1185.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/067_S_1253.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/094_S_4089.png', 1),\n",
       " ('./data/images_gray/GM/CN/axial/094_S_4460.png', 0),\n",
       " ('./data/images_gray/GM/AD/axial/098_S_0149.png', 1),\n",
       " ('./data/images_gray/GM/CN/axial/098_S_0172.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/100_S_0015.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/100_S_0047.png', 0),\n",
       " ('./data/images_gray/GM/AD/axial/100_S_1062.png', 1),\n",
       " ('./data/images_gray/GM/CN/axial/100_S_1286.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/123_S_0072.png', 0),\n",
       " ('./data/images_gray/GM/AD/axial/123_S_0088.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/123_S_0091.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/123_S_0094.png', 1),\n",
       " ('./data/images_gray/GM/CN/axial/123_S_0106.png', 0),\n",
       " ('./data/images_gray/GM/AD/axial/123_S_0162.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/126_S_0606.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/126_S_0784.png', 1),\n",
       " ('./data/images_gray/GM/CN/axial/127_S_0259.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/127_S_0260.png', 0),\n",
       " ('./data/images_gray/GM/AD/axial/127_S_0754.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/127_S_0844.png', 1),\n",
       " ('./data/images_gray/GM/CN/axial/129_S_4369.png', 0),\n",
       " ('./data/images_gray/GM/AD/axial/130_S_0956.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/130_S_4730.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/131_S_0691.png', 1),\n",
       " ('./data/images_gray/GM/CN/axial/133_S_0525.png', 0),\n",
       " ('./data/images_gray/GM/AD/axial/003_S_6264.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/003_S_6833.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/006_S_6689.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/011_S_0010.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/011_S_0183.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/011_S_6303.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/013_S_6768.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/013_S_6975.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/016_S_0991.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/016_S_4963.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/016_S_5032.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/016_S_5057.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/016_S_5251.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/016_S_6708.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/016_S_6839.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/018_S_0335.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/018_S_0633.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/018_S_0682.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/018_S_4733.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/018_S_5074.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/018_S_5240.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/019_S_4477.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/019_S_5012.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/019_S_5019.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/019_S_6573.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/019_S_6585.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/019_S_6712.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/020_S_0213.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/021_S_0343.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/021_S_0642.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/021_S_0753.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/021_S_1109.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/021_S_4718.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/021_S_4924.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/022_S_0007.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/022_S_0129.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/022_S_0219.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/022_S_0543.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/022_S_6013.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/022_S_6796.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/023_S_0083.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/023_S_0084.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/023_S_0093.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/023_S_0916.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/023_S_1262.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/023_S_4501.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/023_S_5120.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/023_S_5241.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/023_S_6661.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/024_S_1171.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/024_S_1307.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/024_S_4223.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/024_S_4280.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/024_S_4905.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/024_S_5054.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/027_S_0404.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/027_S_0850.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/027_S_1082.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/027_S_1254.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/027_S_4801.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/027_S_4802.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/027_S_4938.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/027_S_4962.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/027_S_4964.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/027_S_6648.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/027_S_6733.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/027_S_6849.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/027_S_6965.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/029_S_0836.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/029_S_0999.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/029_S_1056.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/029_S_1184.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/029_S_4307.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/031_S_0321.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/031_S_0554.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/031_S_0773.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/031_S_4024.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/032_S_1101.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/032_S_4755.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/032_S_6600.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/032_S_6602.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/032_S_6855.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/033_S_0724.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/033_S_0733.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/033_S_0739.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/033_S_0888.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/033_S_0889.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/033_S_1087.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/033_S_1281.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/033_S_1283.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/033_S_1285.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/033_S_1308.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/033_S_5013.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/033_S_5017.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/033_S_5087.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/033_S_6705.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/033_S_6824.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/033_S_6976.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/033_S_7066.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/035_S_0341.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/035_S_4783.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/035_S_6650.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/035_S_6660.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/035_S_6927.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/035_S_7001.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/036_S_0577.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/036_S_0759.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/036_S_0760.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/036_S_1001.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/036_S_4740.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/036_S_4820.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/036_S_4894.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/036_S_5063.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/036_S_5112.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/036_S_5149.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/036_S_5210.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/036_S_6179.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/036_S_6231.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/037_S_0627.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/037_S_4001.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/037_S_4770.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/037_S_4879.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/037_S_5162.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/037_S_6216.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/037_S_6230.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/037_S_6377.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/041_S_1368.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/041_S_1391.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/041_S_1435.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/051_S_1296.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/051_S_4980.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/051_S_5005.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/052_S_4959.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/052_S_5062.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/052_S_6305.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/053_S_1044.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/053_S_5070.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/053_S_5208.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/053_S_7109.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/057_S_0474.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/057_S_1371.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/057_S_1373.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/057_S_1379.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/057_S_4110.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/057_S_6746.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/057_S_6869.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/062_S_0535.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/062_S_0690.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/062_S_0730.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/062_S_0793.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/067_S_0020.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/067_S_0029.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/067_S_0076.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/067_S_0110.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/067_S_0828.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/067_S_4728.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/067_S_5205.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/067_S_7033.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/068_S_4859.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/068_S_4968.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/068_S_5146.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/068_S_5206.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/070_S_4692.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/070_S_4719.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/073_S_0565.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/073_S_1207.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/073_S_4853.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/073_S_5016.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/073_S_5090.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/082_S_1079.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/082_S_1377.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/082_S_5029.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/082_S_5184.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/082_S_6690.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/094_S_1027.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/094_S_1090.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/094_S_1102.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/094_S_1164.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/094_S_1397.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/094_S_1402.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/094_S_4282.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/094_S_4737.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/094_S_6736.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/098_S_0884.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/098_S_4201.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/098_S_4215.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/098_S_6601.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/098_S_6655.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/098_S_6658.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/099_S_0372.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/099_S_0470.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/099_S_0492.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/099_S_1144.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/099_S_4124.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/099_S_4994.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/100_S_5106.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/100_S_6713.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/109_S_0777.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/109_S_1157.png', 1),\n",
       " ('./data/images_gray/GM/AD/axial/109_S_1192.png', 1),\n",
       " ('./data/images_gray/GM/CN/axial/002_S_6007.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/002_S_6009.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/002_S_6030.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/002_S_6066.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/002_S_6103.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/002_S_6404.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/002_S_6456.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/002_S_6680.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/003_S_0931.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/003_S_6014.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/003_S_6067.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/003_S_6092.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/003_S_6256.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/003_S_6257.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/003_S_6259.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/003_S_6260.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/003_S_6307.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/003_S_6490.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/003_S_6644.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/003_S_6915.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/003_S_6924.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/003_S_6959.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/003_S_6996.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/003_S_7010.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/005_S_6084.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/005_S_6093.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/005_S_6393.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/006_S_6209.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/006_S_6234.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/006_S_6277.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/006_S_6375.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/006_S_6500.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/007_S_6120.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/007_S_6255.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/007_S_6310.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/007_S_6323.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/007_S_6455.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/007_S_6515.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/007_S_6521.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/009_S_6163.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/009_S_6212.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/009_S_6286.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/010_S_6567.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/011_S_0002.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/011_S_6367.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/011_S_6418.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/011_S_6465.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/011_S_6714.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/011_S_7028.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/011_S_7048.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/011_S_7112.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/012_S_4642.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/012_S_4643.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/013_S_0502.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/013_S_0575.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/013_S_1035.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/013_S_4579.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/013_S_4580.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/013_S_4616.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/013_S_6780.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/013_S_7103.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/014_S_0519.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/014_S_0520.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/014_S_0548.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/014_S_0558.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/014_S_4080.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/014_S_4093.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/014_S_4401.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/014_S_4576.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/014_S_4577.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/014_S_6076.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/014_S_6145.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/014_S_6148.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/014_S_6199.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/014_S_6210.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/014_S_6366.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/014_S_6424.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/014_S_6437.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/014_S_6502.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/014_S_6522.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/014_S_6831.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/014_S_6920.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/014_S_6935.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/014_S_6988.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/014_S_7072.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/014_S_7080.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/016_S_0359.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/016_S_0538.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/016_S_4097.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/016_S_4638.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/016_S_4688.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/016_S_4951.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/016_S_4952.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/016_S_6381.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/016_S_6773.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/016_S_6790.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/016_S_6802.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/016_S_6834.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/016_S_6853.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/016_S_6892.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/016_S_6931.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/016_S_6934.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/016_S_6941.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/016_S_6943.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/016_S_6971.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/018_S_0043.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/018_S_0055.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/018_S_0369.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/018_S_4257.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/018_S_4313.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/018_S_4349.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/018_S_4399.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/018_S_4400.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/018_S_6207.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/018_S_6351.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/019_S_4367.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/019_S_4835.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/019_S_6186.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/019_S_7016.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/020_S_0097.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/020_S_0883.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/020_S_0899.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/020_S_6185.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/020_S_6227.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/020_S_6282.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/020_S_6358.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/020_S_6449.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/020_S_6470.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/020_S_6504.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/020_S_6513.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/020_S_6566.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/021_S_0159.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/021_S_0337.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/021_S_0647.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/021_S_0984.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/021_S_4254.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/021_S_4276.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/021_S_4335.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/021_S_4421.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/021_S_4558.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/021_S_6312.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/021_S_6896.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/021_S_6910.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/021_S_6914.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/021_S_6918.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/021_S_6940.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/021_S_6987.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/021_S_6994.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/021_S_7045.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/021_S_7055.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/021_S_7062.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/021_S_7092.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/022_S_0014.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/022_S_0066.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/022_S_0096.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/022_S_0130.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/022_S_4173.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/022_S_4196.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/022_S_4266.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/022_S_4291.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/022_S_4320.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/022_S_6069.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/022_S_6797.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/022_S_6822.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/023_S_0058.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/023_S_0081.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/023_S_0926.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/023_S_0963.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/023_S_1190.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/023_S_1306.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/023_S_4020.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/023_S_4164.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/023_S_4448.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/023_S_6270.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/023_S_6346.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/023_S_6374.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/023_S_6399.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/023_S_6400.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/023_S_6547.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/023_S_6795.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/024_S_0985.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/024_S_1063.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/024_S_4084.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/024_S_4158.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/024_S_6005.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/024_S_6184.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/024_S_6202.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/024_S_6385.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/024_S_6472.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/027_S_0074.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/027_S_0118.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/027_S_0120.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/027_S_0403.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/027_S_6001.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/027_S_6183.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/027_S_6317.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/027_S_6327.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/027_S_6516.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/027_S_6577.png', 0),\n",
       " ('./data/images_gray/GM/CN/axial/027_S_6582.png', 0)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []# List of tuples (image_path, label)\n",
    "for i in range(0,len(paths)):\n",
    "    data.append((paths[i],new_labels[i]))\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1256651",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hedieh/.local/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hedieh/.local/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from PIL import Image\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "# Define the ResNet-18 model\n",
    "model = models.resnet18(pretrained=True)\n",
    "model\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b11fa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data loader and transformations\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path, label = self.data[index]\n",
    "#         img = Image.open(img_path)\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f007667c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "#     transforms.Resize(256),\n",
    "#     transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25232a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import torchvision.transforms as transforms\n",
    "# from torchvision.datasets import ImageFolder\n",
    "# from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "# from sklearn.model_selection import KFold\n",
    "# from torchvision.models import resnet18\n",
    "\n",
    "# # Define the DeepSVM model with ResNet18 as the base\n",
    "# class DeepSVM_ResNet(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(DeepSVM_ResNet, self).__init__()\n",
    "#         self.resnet = resnet18(pretrained=True)\n",
    "#         self.svm = nn.Linear(1000, 3)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.resnet(x)\n",
    "#         return self.svm(x)\n",
    "\n",
    "# # Define the loss function\n",
    "# def hinge_loss(scores, targets):\n",
    "#     margin = 1 - scores * targets\n",
    "#     return torch.mean(torch.max(torch.zeros(margin.size()), margin))\n",
    "\n",
    "# # Define the training function\n",
    "# def train(model, optimizer, x, y):\n",
    "# #     x = x.to(device)\n",
    "# #     y = y.to(device)\n",
    "#     optimizer.zero_grad()\n",
    "#     scores = model(x)\n",
    "#     loss = hinge_loss(scores.view(-1), y)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4afd80f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path, label = self.data[index]\n",
    "#         img = Image.open(img_path)\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "149d25c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21721010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import torchvision.transforms as transforms\n",
    "# from torchvision.datasets import ImageFolder\n",
    "# from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
    "# from torchvision.models import resnet18\n",
    "\n",
    "# # Define the DeepSVM model with ResNet18 as the base\n",
    "# class DeepSVM_ResNet(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(DeepSVM_ResNet, self).__init__()\n",
    "#         self.resnet = resnet18(pretrained=True)\n",
    "#         self.svm = nn.Linear(1000, 3)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.resnet(x)\n",
    "#         return self.svm(x)\n",
    "\n",
    "# # Define the loss function\n",
    "# def hinge_loss(scores, targets):\n",
    "#     margin = 1 - scores * targets\n",
    "#     return torch.mean(torch.max(torch.zeros(margin.size()), margin))\n",
    "\n",
    "# # Define the training function\n",
    "# def train(model, optimizer, x, y):\n",
    "#     x = x.to(device)\n",
    "#     y = y.to(device)\n",
    "#     optimizer.zero_grad()\n",
    "#     scores = model(x)\n",
    "#     loss = hinge_loss(scores.view(-1), y)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     return loss.item()\n",
    "\n",
    "# # Set device\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# # Load data\n",
    "# # data_dir = 'path/to/data'\n",
    "# # dataset = ImageFolder(data_dir, transform=transforms.Compose([\n",
    "# #     transforms.Resize((256, 256)),\n",
    "# #     transforms.ToTensor(),\n",
    "# # ]))\n",
    "# # labels = [0] * len(dataset)\n",
    "# kf = KFold(n_splits=5, shuffle=True)\n",
    "# train_losses = []\n",
    "# test_losses = []\n",
    "# train_accs = []\n",
    "# test_accs = []\n",
    "# train_f1s = []\n",
    "# test_f1s = []\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# for fold, (train_idx, test_idx) in enumerate(kf.split(data)):\n",
    "#     print(f'Fold {fold+1}')\n",
    "#     train_data = [data[i] for i in train_idx]\n",
    "#     val_data = [data[i] for i in test_idx]\n",
    "# #     train_sampler = SubsetRandomSampler(train_idx)\n",
    "# #     test_sampler = SubsetRandomSampler(test_idx)\n",
    "# #     train_loader = DataLoader(dataset, batch_size=64, sampler=train_sampler)\n",
    "# #     test_loader = DataLoader(dataset, batch_size=64, sampler=test_sampler)\n",
    "#     train_dataset = ImageDataset(train_data, transform=transform)\n",
    "#     val_dataset = ImageDataset(val_data, transform=transform)\n",
    "#     train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "#     val_loader = DataLoader(val_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "#     # Initialize the model and optimizer\n",
    "#     model = DeepSVM_ResNet().to(device)\n",
    "#     optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "#     # Train the model\n",
    "#     for epoch in range(10):\n",
    "#         train_loss = 0\n",
    "#         train_preds = []\n",
    "#         train_targets = []\n",
    "#         for images, labels in train_loader:\n",
    "# #             loss = train(model, optimizer, images, labels)\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(images)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             train_loss += loss.item()\n",
    "#             optimizer.step()\n",
    "#             train_preds.extend(output.argmax(dim=1).tolist())\n",
    "#             train_targets.extend(labels.tolist())\n",
    "# #         for batch_idx, (data, target) in enumerate(train_loader):\n",
    "# #             loss = train(model, optimizer, data, target)\n",
    "# #             train_loss += loss\n",
    "# #             train_preds.extend(model(data).argmax(dim=1).tolist())\n",
    "# #             train_targets.extend(target.tolist())\n",
    "#         train_loss /= len(train_loader)\n",
    "#         train_losses.append(train_loss)\n",
    "#         train_acc = accuracy_score(train_targets, train_preds)\n",
    "#         train_f1 = f1_score(train_targets, train_preds, average='weighted')\n",
    "#         train_accs.append(train_acc)\n",
    "#         train_f1s.append(train_f1)\n",
    "#         print(f'Epoch: {epoch}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Train F1: {train_f1:.4f}')\n",
    "\n",
    "#     # Evaluate the model on test data\n",
    "#     test_loss = 0\n",
    "#     test_preds = []\n",
    "#     test_targets = []\n",
    "#     with torch.no_grad():\n",
    "#         for images, labels in val_loader:\n",
    "# #             images = images.to(device)\n",
    "# #             labels = labels.to(device)\n",
    "# #             scores = model(images)\n",
    "# #             loss = hinge_loss(scores.view(-1), labels)\n",
    "# #             test_loss += loss.item() * images.size(0)\n",
    "# #             pred = scores.argmax(dim=1)\n",
    "# #             test_preds.extend(pred.tolist())\n",
    "# #             test_targets.extend(target.tolist())\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(images)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             test_loss += loss.item()\n",
    "#             optimizer.step()\n",
    "#             test_preds.extend(output.argmax(dim=1).tolist())\n",
    "#             test_targets.extend(labels.tolist())\n",
    "# #         for data, target in test_loader:\n",
    "# #             data = data.to(device)\n",
    "# #             target = target.to(device)\n",
    "# #             scores = model(data)\n",
    "# #             loss = hinge_loss(scores.view(-1), target)\n",
    "# #             test_loss += loss.item() * data.size(0)\n",
    "# #             pred = scores.argmax(dim=1)\n",
    "# #             test_preds.extend(pred.tolist())\n",
    "# #             test_targets.extend(target.tolist())\n",
    "#         test_loss /= len(test_loader.dataset)\n",
    "#         test_losses.append(test_loss)\n",
    "#         test_acc = accuracy_score(test_targets, test_preds)\n",
    "#         test_f1 = f1_score(test_targets, test_preds, average='weighted')\n",
    "#         test_accs.append(test_acc)\n",
    "#         test_f1s.append(test_f1)\n",
    "#         print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}, Test F1: {test_f1:.4f}')\n",
    "\n",
    "#     # Print confusion matrix\n",
    "#     cm = confusion_matrix(test_targets, test_preds)\n",
    "#     print(f'Confusion Matrix:\\n{cm}')\n",
    "\n",
    "# print(f'Average Train Loss: {sum(train_losses)/len(train_losses):.4f}')\n",
    "# print(f'Average Test Loss: {sum(test_losses)/len(test_losses):.4f}')\n",
    "# print(f'Average Train Accuracy: {sum(train_accs)/len(train_accs):.4f}')\n",
    "# print(f'Average Test Accuracy: {sum(test_accs)/len(test_accs):.4f}')\n",
    "# print(f'Average Train F1 Score: {sum(train_f1s)/len(train_f1s):.4f}')\n",
    "# print(f'Average Test F1 Score: {sum(test_f1s)/len(test_f1s):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74077808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the data and split into k folds\n",
    "# k = 5\n",
    "# kf = KFold(n_splits=k, shuffle=True)\n",
    "# from torch.nn import functional as F\n",
    "\n",
    "\n",
    "# # Define the loss function and optimizer\n",
    "# # criterion = nn.CrossEntropyLoss()\n",
    "# criterion = nn.MultiLabelMarginLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# # optimizer = optim.SGD(model.parameters(), momentum=0.99, lr=0.001)\n",
    "\n",
    "# # Define the learning rate scheduler\n",
    "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.9)\n",
    "\n",
    "# for fold, (train_idx, val_idx) in enumerate(kf.split(data)):\n",
    "#     train_data = [data[i] for i in train_idx]\n",
    "#     val_data = [data[i] for i in val_idx]\n",
    "    \n",
    "#     # Define the data loaders\n",
    "#     train_dataset = ImageDataset(train_data, transform=transform)\n",
    "#     val_dataset = ImageDataset(val_data, transform=transform)\n",
    "#     train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "#     val_loader = DataLoader(val_dataset, batch_size=8, shuffle=True)\n",
    "    \n",
    "#     # Define the model\n",
    "#     model = models.resnet18(pretrained=True)\n",
    "#     num_ftrs = model.fc.in_features\n",
    "#     for param in model.parameters():\n",
    "#         param.requires_grad = False\n",
    "#     model.fc = nn.Sequential(nn.Linear(model.fc.in_features, 3),\n",
    "# #                               nn.BatchNorm1d(128),\n",
    "# #                               nn.ReLU(inplace=True),\n",
    "# #                               nn.Dropout(p=0.1),\n",
    "# #                               nn.Linear(512,128),\n",
    "# # #                               nn.BatchNorm1d(3),\n",
    "# #                               nn.ReLU(inplace=True),\n",
    "# # #                               nn.Dropout(p=0.1),\n",
    "# #                               nn.Linear(128,3),\n",
    "# #                               nn.ReLU(inplace=True),\n",
    "# #                               nn.Dropout(p=0.1),\n",
    "#                               nn.Softmax(dim=1))\n",
    "\n",
    "#     # Train the model\n",
    "#     for epoch in range(30):\n",
    "#         model.train()\n",
    "#         train_loss = 0\n",
    "#         train_correct = 0\n",
    "#         train_f1 = 0\n",
    "#         for images, labels in train_loader:\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(images)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "# #             torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n",
    "# #             torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "#             optimizer.step()\n",
    "#             train_loss += loss.item()\n",
    "#             _, predicted = torch.max(outputs.data, 1)\n",
    "#             train_correct += (predicted == labels).sum().item()\n",
    "#             train_f1 += f1_score(labels.cpu().numpy(), predicted.cpu().numpy(), average='macro')\n",
    "\n",
    "#         # Evaluate the model on the validation set\n",
    "#         model.eval()\n",
    "#         with torch.no_grad():\n",
    "#             val_loss = 0\n",
    "#             val_correct = 0\n",
    "#             val_f1 = 0\n",
    "#             for images, labels in val_loader:\n",
    "#                 outputs = model(images)\n",
    "#                 loss = criterion(outputs, labels)\n",
    "#                 val_loss += loss.item()\n",
    "#                 _, predicted = torch.max(outputs.data, 1)\n",
    "#                 val_correct += (predicted == labels).sum().item()\n",
    "#                 val_f1 += f1_score(labels.cpu().numpy(), predicted.cpu().numpy(), average='macro')\n",
    "#             train_acc = 100 * train_correct / len(train_dataset)\n",
    "#             train_f1 = 100 * train_f1 / len(train_loader)\n",
    "#             val_acc = 100 * val_correct / len(val_dataset)\n",
    "#             val_f1 = 100 * val_f1 / len(val_loader)\n",
    "#             print(f'Fold {fold+1}, Epoch {epoch+1}, Train Accuracy: {train_acc:.2f}%, Train F1 Score: {train_f1:.2f}%, Train Loss: {train_loss:.4f}, Validation Accuracy: {val_acc:.2f}%, Validation F1 Score: {val_f1:.2f}%, Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "#         # Update the learning rate\n",
    "#         exp_lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ca742f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hedieh/.local/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hedieh/.local/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, Train Accuracy: 0.54%, Train F1 Score: 0.52%\n",
      "Fold 1, Test Accuracy: 0.50%, Test F1 Score: 0.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hedieh/.local/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hedieh/.local/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 54\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     53\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 54\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     57\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchvision/models/resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchvision/models/resnet.py:273\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    270\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m    271\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxpool(x)\n\u001b[0;32m--> 273\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n\u001b[1;32m    275\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchvision/models/resnet.py:96\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     93\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(out)\n\u001b[1;32m     94\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[0;32m---> 96\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(out)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Define the SVM classifier and its hyperparameters\n",
    "clf = svm.SVC(kernel='linear', C=1, gamma='auto',decision_function_shape='ovo')\n",
    "\n",
    "\n",
    "k = 5\n",
    "kf = StratifiedKFold(n_splits=k, shuffle=True)\n",
    "\n",
    "# Train the model using k-fold cross-validation\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(data,new_labels)):\n",
    "    train_data = [data[i] for i in train_idx]\n",
    "    val_data = [data[j] for j in val_idx]\n",
    "    \n",
    "    # Define the data loaders\n",
    "    train_dataset = ImageDataset(train_data, transform=transform)\n",
    "    val_dataset = ImageDataset(val_data, transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=True)\n",
    "    \n",
    "    # Define the model\n",
    "    model = torchvision.models.resnet18(pretrained=True)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    model.fc = nn.Sequential(nn.Linear(model.fc.in_features, 150),\n",
    "                              nn.ReLU(inplace=True))\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "#     optimizer = optim.SGD(model.parameters(), momentum=0.9, lr=0.001)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Train the model on the training set\n",
    "    # Extract the 128 features from the model for each image in the dataset\n",
    "    train_features = []\n",
    "    train_labels = []\n",
    "    for epoch in range(30):\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            train_features.append(outputs.detach().numpy())\n",
    "            train_labels.append(labels.numpy())\n",
    "            optimizer.step()\n",
    "#         print(outputs.shape)\n",
    "#         print(len(train_features))\n",
    "    train_features = np.array(train_features)\n",
    "    train_features.shape\n",
    "    train_labels = np.array(train_labels)\n",
    "    n,x,y = train_features.shape\n",
    "    train_features = train_features.reshape(n*x,y)\n",
    "#     print(train_features.shape)\n",
    "#     print(f\"label:{train_features.shape}\")\n",
    "    n,x = train_labels.shape\n",
    "    train_labels = train_labels.reshape(n*x)\n",
    "#     print(train_labels.shape)\n",
    "\n",
    "    # Train the SVM classifier on the 128-dimensional feature vectors\n",
    "    clf.fit(train_features, train_labels)\n",
    "\n",
    "    # Evaluate the model on the training set\n",
    "#     train_features = []\n",
    "#     train_labels = []\n",
    "#     for images, labels in train_loader:\n",
    "#         outputs = model(images)\n",
    "#         train_features.append(outputs.detach().numpy())\n",
    "#         train_labels.eappend(labels.numpy())\n",
    "#     train_features = np.array(train_features)\n",
    "#     train_labels = np.array(train_labels)\n",
    "    train_acc = clf.score(train_features, train_labels)\n",
    "    train_f1 = f1_score(train_labels, clf.predict(train_features), average='macro')\n",
    "    print(f'Fold {fold+1}, Train Accuracy: {train_acc:.2f}%, Train F1 Score: {train_f1:.2f}%')\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_features = []\n",
    "    test_labels = []\n",
    "    for images, labels in val_loader:\n",
    "        outputs = model(images)\n",
    "        test_features.extend(outputs.detach().numpy())\n",
    "        test_labels.extend(labels.numpy())\n",
    "#     print(test_features)\n",
    "    test_features = np.array(test_features)\n",
    "    test_labels = np.array(test_labels)\n",
    "#     print(test_features.shape)\n",
    "#     test_features = test_features.reshape(n*x,y)\n",
    "#     print(test_features.shape)\n",
    "#     print(f\"label:{test_features.shape}\")\n",
    "#     n,x = test_labels.shape\n",
    "#     test_labels = test_labels.reshape(n*x)\n",
    "#     print(test_labels.shape)\n",
    "    test_acc = clf.score(test_features, test_labels)\n",
    "    test_f1 = f1_score(test_labels, clf.predict(test_features), average='macro')\n",
    "    print(f'Fold {fold+1}, Test Accuracy: {test_acc:.2f}%, Test F1 Score: {test_f1:.2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af169077",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e9098e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array(test_features[1:6]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5609e591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45ec16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_features[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f44923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = 0\n",
    "# for images,labels in train_loader:\n",
    "#     a+=1\n",
    "    \n",
    "# print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51f7344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0e7ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
